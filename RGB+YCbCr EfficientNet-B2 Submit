import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import os
from tqdm import tqdm
import warnings
import timm
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Set random seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

def crop_black_background(image, threshold=10):
    """
    Crop black background from retinal images
    """
    # Convert to grayscale for processing
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image
    
    # Create mask for non-black pixels
    mask = gray > threshold
    
    # Find bounding box of non-black region
    coords = np.argwhere(mask)
    if len(coords) == 0:
        return image  # Return original if no non-black pixels found
    
    y0, x0 = coords.min(axis=0)
    y1, x1 = coords.max(axis=0) + 1
    
    # Crop the image
    cropped = image[y0:y1, x0:x1]
    
    return cropped

class EfficientNetB2Backbone(nn.Module):
    """
    EfficientNet-B2 backbone wrapper for feature extraction
    """
    def __init__(self, pretrained=False):
        super(EfficientNetB2Backbone, self).__init__()
        self.model = timm.create_model('efficientnet_b2', pretrained=pretrained, num_classes=0)
        self.feature_dim = self.model.num_features
        
    def forward(self, x):
        return self.model(x)

class EnhancedDualStreamFusionEfficientNet(nn.Module):
    """
    Enhanced fusion with attention mechanism using EfficientNet-B2 backbones
    """
    def __init__(self, num_classes=5, dropout_rate=0.5):
        super(EnhancedDualStreamFusionEfficientNet, self).__init__()
        
        # RGB stream with EfficientNet-B2
        self.rgb_backbone = EfficientNetB2Backbone(pretrained=False)
        
        # YCbCr stream with EfficientNet-B2
        self.ycbcr_backbone = EfficientNetB2Backbone(pretrained=False)
        
        # Get feature dimensions from EfficientNet-B2
        rgb_features = 1408  # EfficientNet-B2 feature dimension
        ycbcr_features = 1408
        
        # Attention mechanism for feature fusion
        self.attention = nn.Sequential(
            nn.Linear(rgb_features + ycbcr_features, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(512, 2),
            nn.Softmax(dim=1)
        )
        
        # Final classifier
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(rgb_features + ycbcr_features, 1024),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(1024),
            nn.Dropout(dropout_rate/2),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(512),
            nn.Dropout(dropout_rate/2),
            nn.Linear(512, num_classes)
        )
        
    def forward(self, x):
        rgb, ycbcr = x
        
        rgb_features = self.rgb_backbone(rgb)
        ycbcr_features = self.ycbcr_backbone(ycbcr)
        
        # Concatenate features
        combined = torch.cat([rgb_features, ycbcr_features], dim=1)
        
        # Calculate attention weights
        attention_weights = self.attention(combined)
        
        # Apply attention
        weighted_rgb = attention_weights[:, 0:1] * rgb_features
        weighted_ycbcr = attention_weights[:, 1:2] * ycbcr_features
        
        # Final fusion
        fused_features = torch.cat([weighted_rgb, weighted_ycbcr], dim=1)
        
        return self.classifier(fused_features)

class DiabeticRetinopathyRGBYCbCrTestDataset(Dataset):
    """
    Test Dataset for Diabetic Retinopathy with RGB + YCbCr fusion
    """
    def __init__(self, csv_file, img_dir, image_size=384):
        """
        Args:
            csv_file (string): Path to csv with image names
            img_dir (string): Directory with all images
            image_size (int): Target image size (384x384)
        """
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.image_size = image_size
        
        print(f"Test dataset loaded: {len(self.data)} images")
        
    def __len__(self):
        return len(self.data)
    
    def preprocess_image(self, image_path):
        """
        Enhanced preprocessing with black background cropping
        """
        # Load image
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Could not load image: {image_path}")
        
        # Convert BGR to RGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Crop black background
        image = crop_black_background(image, threshold=10)
        
        # Resize to target size
        image = cv2.resize(image, (self.image_size, self.image_size))
        
        return image
    
    def rgb_to_ycbcr_tensor(self, rgb_image):
        """
        Convert RGB image to YCbCr
        """
        # Convert RGB to YCbCr using cv2
        ycbcr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2YCrCb)
        return ycbcr_image
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        # Get image name
        img_name = self.data.iloc[idx, 0]  # First column should be image ID
        
        # Try different extensions
        img_extensions = ['.jpeg', '.jpg', '.png']
        img_path = None
        
        for ext in img_extensions:
            potential_path = os.path.join(self.img_dir, f"{img_name}{ext}")
            if os.path.exists(potential_path):
                img_path = potential_path
                break
                
        if img_path is None:
            raise FileNotFoundError(f"Image {img_name} not found with any extension")
        
        # Load and preprocess image
        rgb_image = self.preprocess_image(img_path)
        
        # Convert to YCbCr
        ycbcr_image = self.rgb_to_ycbcr_tensor(rgb_image)
        
        # Convert to tensors
        rgb_tensor = torch.from_numpy(rgb_image.transpose(2, 0, 1)).float() / 255.0
        ycbcr_tensor = torch.from_numpy(ycbcr_image.transpose(2, 0, 1)).float() / 255.0
        
        # Normalize both with ImageNet stats
        rgb_tensor = transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        )(rgb_tensor)
        
        ycbcr_tensor = transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        )(ycbcr_tensor)
        
        return (rgb_tensor, ycbcr_tensor), img_name

def load_trained_model(model_path, num_classes=5, dropout_rate=0.5):
    """
    Load the pre-trained RGB+YCbCr dual-stream model
    """
    print(f"Loading model from: {model_path}")
    
    # Initialize model architecture
    model = EnhancedDualStreamFusionEfficientNet(
        num_classes=num_classes,
        dropout_rate=dropout_rate
    )
    
    # Load trained weights
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint)
    
    model.to(device)
    model.eval()
    
    print("Model loaded successfully!")
    return model

def generate_predictions(model, test_loader, use_tta=False):
    """
    Generate predictions for test set
    
    Args:
        model: Trained model
        test_loader: DataLoader for test set
        use_tta: Whether to use Test Time Augmentation (TTA)
    """
    model.eval()
    predictions = []
    image_names = []
    all_probabilities = []
    
    print("Generating predictions...")
    
    with torch.no_grad():
        for (rgb_data, ycbcr_data), names in tqdm(test_loader, desc="Processing test images"):
            rgb_data = rgb_data.to(device)
            ycbcr_data = ycbcr_data.to(device)
            
            if use_tta:
                # Test Time Augmentation
                outputs = model((rgb_data, ycbcr_data))
                
                # Horizontal flip
                outputs += model((torch.flip(rgb_data, dims=[3]), torch.flip(ycbcr_data, dims=[3])))
                
                # Vertical flip
                outputs += model((torch.flip(rgb_data, dims=[2]), torch.flip(ycbcr_data, dims=[2])))
                
                # Average the predictions
                outputs = outputs / 3.0
            else:
                outputs = model((rgb_data, ycbcr_data))
            
            # Convert logits to probabilities
            probs = torch.softmax(outputs, dim=1)
            
            # Get predicted classes
            preds = probs.argmax(dim=1)
            
            predictions.extend(preds.cpu().numpy())
            image_names.extend(names)
            all_probabilities.extend(probs.cpu().numpy())
    
    return predictions, image_names, np.array(all_probabilities)

def create_submission_file(predictions, image_names, output_file='submission.csv'):
    """
    Create submission file in Kaggle format
    """
    submission_df = pd.DataFrame({
        'id_code': image_names,
        'diagnosis': predictions
    })
    
    # Sort by id_code to ensure consistent ordering
    submission_df = submission_df.sort_values('id_code')
    
    # Save to CSV
    submission_df.to_csv(output_file, index=False)
    
    print(f"Submission file saved: {output_file}")
    print(f"Total predictions: {len(submission_df)}")
    
    # Print prediction distribution
    print("\nPrediction distribution:")
    label_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative']
    for i, label in enumerate(label_names):
        count = (submission_df['diagnosis'] == i).sum()
        percentage = count / len(submission_df) * 100
        print(f"  Class {i} ({label}): {count} images ({percentage:.1f}%)")
    
    return submission_df

def main():
    """
    Main inference pipeline for RGB+YCbCr EfficientNetB2 model
    """
    # Configuration
    config = {
        'model_path': '/kaggle/input/rgb-ycbcr-final-efficientnetb2-training/best_dual_stream_efficientnet_model.pth',
        'test_csv': '/kaggle/input/aptos2019-blindness-detection/test.csv',
        'test_img_dir': '/kaggle/input/aptos2019-blindness-detection/test_images',
        'batch_size': 16,
        'num_classes': 5,
        'dropout_rate': 0.5,
        'use_tta': True,  # Use Test Time Augmentation for better results
        'output_file': 'submission.csv',
        'image_size': 384
    }
    
    print("="*70)
    print("DIABETIC RETINOPATHY RGB+YCbCr EfficientNetB2 MODEL - INFERENCE")
    print("="*70)
    print("Configuration:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    print("="*70)
    
    # Check if test files exist
    if not os.path.exists(config['test_csv']):
        print(f"Error: Test CSV file not found at {config['test_csv']}")
        return
    
    if not os.path.exists(config['test_img_dir']):
        print(f"Error: Test images directory not found at {config['test_img_dir']}")
        return
    
    if not os.path.exists(config['model_path']):
        print(f"Error: Model file not found at {config['model_path']}")
        return
    
    # Load trained model
    model = load_trained_model(
        config['model_path'], 
        config['num_classes'], 
        config['dropout_rate']
    )
    
    # Load test dataset
    print("\nLoading test data...")
    test_dataset = DiabeticRetinopathyRGBYCbCrTestDataset(
        csv_file=config['test_csv'],
        img_dir=config['test_img_dir'],
        image_size=config['image_size']
    )
    
    # Create test data loader
    test_loader = DataLoader(
        test_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=4,
        pin_memory=True
    )
    
    # Generate predictions
    print(f"\nGenerating predictions with TTA: {config['use_tta']}")
    predictions, image_names, probabilities = generate_predictions(
        model, 
        test_loader, 
        use_tta=config['use_tta']
    )
    
    # Create submission file
    print("\nCreating submission file...")
    submission_df = create_submission_file(
        predictions, 
        image_names, 
        config['output_file']
    )
    
    print("\n" + "="*70)
    print("INFERENCE COMPLETED SUCCESSFULLY!")
    print("="*70)
    print(f"Submission file: {config['output_file']}")
    print(f"Total test images processed: {len(predictions)}")
    print("="*70)
    
    return submission_df

if __name__ == "__main__":
    # Run inference
    submission_df = main()
