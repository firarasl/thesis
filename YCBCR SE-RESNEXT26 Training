import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import os
from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
import json
from datetime import datetime
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class DiabeticRetinopathyYCbCrDataset(Dataset):
    """
    Custom Dataset for Diabetic Retinopathy with YCbCr color space
    """
    def __init__(self, csv_file, img_dir, transform=None, is_test=False):
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test
        
        if not is_test:
            print(f"Dataset loaded: {len(self.data)} images")
            label_counts = self.data.iloc[:, 1].value_counts().sort_index()
            print("Label distribution:")
            for label, count in label_counts.items():
                print(f"  Class {label}: {count} images ({count/len(self.data)*100:.1f}%)")
        
    def __len__(self):
        return len(self.data)
    
    def rgb_to_ycbcr(self, rgb_image):
        """
        Convert RGB image to YCbCr color space using OpenCV
        """
        if isinstance(rgb_image, Image.Image):
            rgb_array = np.array(rgb_image)
        else:
            rgb_array = rgb_image
            
        # Convert RGB to YCbCr using OpenCV
        ycbcr_array = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2YCrCb)
        
        # Rearrange to YCbCr format (Y, Cb, Cr)
        y_channel = ycbcr_array[:, :, 0]
        cr_channel = ycbcr_array[:, :, 1]
        cb_channel = ycbcr_array[:, :, 2]
        
        ycbcr_correct = np.stack([y_channel, cb_channel, cr_channel], axis=2)
        
        return Image.fromarray(ycbcr_correct)
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        img_name = self.data.iloc[idx, 0]
        img_extensions = ['.jpeg', '.jpg', '.png']
        img_path = None
        
        for ext in img_extensions:
            potential_path = os.path.join(self.img_dir, f"{img_name}{ext}")
            if os.path.exists(potential_path):
                img_path = potential_path
                break
                
        if img_path is None:
            raise FileNotFoundError(f"Image {img_name} not found with any extension")
        
        # Load image and convert to YCbCr
        image = cv2.imread(img_path)
        if image is None:
            raise ValueError(f"Could not load image: {img_path}")
        
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = Image.fromarray(image)
        image = self.rgb_to_ycbcr(image)
        
        if self.transform:
            image = self.transform(image)
            
        if not self.is_test:
            label = int(self.data.iloc[idx, 1])
            return image, label
        else:
            return image, img_name

class SEBlock(nn.Module):
    """
    Squeeze-and-Excitation Block
    """
    def __init__(self, channels, reduction=16):
        super(SEBlock, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

class ResNeXtBottleneck(nn.Module):
    """
    ResNeXt Bottleneck Block with SE
    """
    expansion = 4

    def __init__(self, in_channels, out_channels, stride=1, cardinality=32, base_width=4):
        super(ResNeXtBottleneck, self).__init__()
        width = int(out_channels * (base_width / 64.)) * cardinality
        
        self.conv1 = nn.Conv2d(in_channels, width, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(width)
        
        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride, 
                              padding=1, groups=cardinality, bias=False)
        self.bn2 = nn.BatchNorm2d(width)
        
        self.conv3 = nn.Conv2d(width, out_channels * self.expansion, kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)
        
        self.se = SEBlock(out_channels * self.expansion)
        
        self.relu = nn.ReLU(inplace=True)
        
        # Shortcut connection
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels * self.expansion:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels * self.expansion, 
                         kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels * self.expansion)
            )

    def forward(self, x):
        residual = self.shortcut(x)
        
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)
        
        out = self.conv3(out)
        out = self.bn3(out)
        
        # Apply SE block
        out = self.se(out)
        
        out += residual
        out = self.relu(out)
        
        return out

class SEResNeXt26(nn.Module):
    """
    SE-ResNeXt26 (26×4d) for YCbCr Diabetic Retinopathy Classification
    """
    def __init__(self, num_classes=5, cardinality=32, base_width=4):
        super(SEResNeXt26, self).__init__()
        self.cardinality = cardinality
        self.base_width = base_width
        
        # Initial layers
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        
        # Residual layers
        self.layer1 = self._make_layer(64, 64, 2, stride=1)
        self.layer2 = self._make_layer(256, 128, 2, stride=2)
        self.layer3 = self._make_layer(512, 256, 2, stride=2)
        self.layer4 = self._make_layer(1024, 512, 2, stride=2)
        
        # Classifier
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.dropout = nn.Dropout(0.5)
        self.fc = nn.Linear(2048, num_classes)
        
        # Initialize weights
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def _make_layer(self, in_channels, out_channels, blocks, stride=1):
        layers = []
        layers.append(ResNeXtBottleneck(in_channels, out_channels, stride, 
                                      self.cardinality, self.base_width))
        
        for _ in range(1, blocks):
            layers.append(ResNeXtBottleneck(out_channels * 4, out_channels, 
                                          1, self.cardinality, self.base_width))
        
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.dropout(x)
        x = self.fc(x)
        
        return x

def get_ycbcr_transforms():
    """
    Define data augmentation and preprocessing transforms for YCbCr images
    """
    ycbcr_mean = [0.5, 0.5, 0.5]
    ycbcr_std = [0.25, 0.25, 0.25]
    
    train_transforms = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomVerticalFlip(p=0.5),
        transforms.RandomRotation(degrees=15),
        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),
        transforms.RandomResizedCrop(512, scale=(0.8, 1.0)),
        transforms.ToTensor(),
        transforms.Normalize(mean=ycbcr_mean, std=ycbcr_std)
    ])
    
    val_transforms = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.ToTensor(),
        transforms.Normalize(mean=ycbcr_mean, std=ycbcr_std)
    ])
    
    return train_transforms, val_transforms

def quadratic_weighted_kappa(y_true, y_pred):
    return cohen_kappa_score(y_true, y_pred, weights='quadratic')

def train_model(model, train_loader, val_loader, num_epochs=60, learning_rate=1e-4):
    """
    Train the SE-ResNeXt26 model
    """
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=10, T_mult=2, eta_min=1e-6
    )
    
    history = {
        'train_losses': [], 'val_losses': [], 'val_kappas': [],
        'val_accuracies': [], 'learning_rates': []
    }
    
    best_kappa = 0.0
    best_model_state = None
    patience_counter = 0
    patience = 15
    
    print("Starting SE-ResNeXt26 YCbCr Model Training...")
    print(f"Training on {len(train_loader.dataset)} samples")
    print(f"Validating on {len(val_loader.dataset)} samples")
    
    for epoch in range(num_epochs):
        # Training
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')
        
        for batch_idx, (data, target) in enumerate(train_pbar):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            
            train_loss += loss.item()
            pred = output.argmax(dim=1, keepdim=True)
            train_correct += pred.eq(target.view_as(pred)).sum().item()
            train_total += target.size(0)
            
            current_acc = 100. * train_correct / train_total
            train_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{current_acc:.2f}%'
            })
        
        avg_train_loss = train_loss / len(train_loader)
        train_accuracy = 100. * train_correct / train_total
        
        # Validation
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')
            for data, target in val_pbar:
                data, target = data.to(device), target.to(device)
                output = model(data)
                loss = criterion(output, target)
                val_loss += loss.item()
                
                pred = output.argmax(dim=1, keepdim=True)
                val_correct += pred.eq(target.view_as(pred)).sum().item()
                val_total += target.size(0)
                
                all_preds.extend(pred.cpu().numpy().flatten())
                all_targets.extend(target.cpu().numpy())
                
                current_acc = 100. * val_correct / val_total
                val_pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{current_acc:.2f}%'
                })
        
        avg_val_loss = val_loss / len(val_loader)
        val_accuracy = 100. * val_correct / val_total
        val_kappa = quadratic_weighted_kappa(all_targets, all_preds)
        
        scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']
        
        history['train_losses'].append(avg_train_loss)
        history['val_losses'].append(avg_val_loss)
        history['val_kappas'].append(val_kappa)
        history['val_accuracies'].append(val_accuracy)
        history['learning_rates'].append(current_lr)
        
        print(f'\nEpoch {epoch+1}/{num_epochs}:')
        print(f'  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.2f}%')
        print(f'  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%')
        print(f'  Val QWK: {val_kappa:.4f}')
        print(f'  Learning Rate: {current_lr:.8f}')
        
        if val_kappa > best_kappa:
            best_kappa = val_kappa
            best_model_state = model.state_dict().copy()
            torch.save(best_model_state, 'best_seresnext26_ycbcr_model.pth')
            patience_counter = 0
            print(f'  ✅ New best model saved! QWK: {best_kappa:.4f}')
        else:
            patience_counter += 1
            
        if patience_counter >= patience:
            print(f'\nEarly stopping triggered after {patience} epochs without improvement.')
            break
            
        print('-' * 70)
    
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    history['best_kappa'] = best_kappa
    history['total_epochs'] = epoch + 1
    
    return model, history

def evaluate_model(model, test_loader, save_predictions=True):
    """
    Evaluate model on test set
    """
    model.eval()
    predictions = []
    image_names = []
    
    print("Generating SE-ResNeXt26 predictions...")
    with torch.no_grad():
        for data, names in tqdm(test_loader):
            data = data.to(device)
            outputs = model(data)
            probs = torch.softmax(outputs, dim=1)
            preds = probs.argmax(dim=1)
            
            predictions.extend(preds.cpu().numpy())
            image_names.extend(names)
    
    if save_predictions:
        submission_df = pd.DataFrame({
            'id_code': image_names,
            'diagnosis': predictions
        })
        submission_df.to_csv('seresnext26_ycbcr_predictions.csv', index=False)
        print("SE-ResNeXt26 predictions saved to 'seresnext26_ycbcr_predictions.csv'")
    
    return predictions, image_names

def validate_with_confusion_matrix(model, val_loader):
    """
    Generate detailed validation metrics
    """
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for data, target in tqdm(val_loader, desc="Generating validation metrics"):
            data, target = data.to(device), target.to(device)
            output = model(data)
            pred = output.argmax(dim=1)
            
            all_preds.extend(pred.cpu().numpy())
            all_targets.extend(target.cpu().numpy())
    
    qwk = quadratic_weighted_kappa(all_targets, all_preds)
    cm = confusion_matrix(all_targets, all_preds)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative'],
                yticklabels=['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative'])
    plt.title(f'SE-ResNeXt26 YCbCr Model Confusion Matrix (QWK: {qwk:.4f})')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.savefig('seresnext26_ycbcr_confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    class_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative']
    report = classification_report(all_targets, all_preds, target_names=class_names)
    print("\nClassification Report:")
    print(report)
    
    return qwk, cm, report

def plot_training_history(history):
    """
    Plot training history
    """
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    ax1.plot(history['train_losses'], label='Training Loss', color='blue')
    ax1.plot(history['val_losses'], label='Validation Loss', color='orange')
    ax1.set_title('SE-ResNeXt26 YCbCr Model: Training and Validation Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True)
    
    ax2.plot(history['val_kappas'], label='Validation QWK', color='green', linewidth=2)
    ax2.axhline(y=0.889, color='red', linestyle='--', label='Target QWK (0.889)', linewidth=2)
    ax2.set_title('SE-ResNeXt26 YCbCr Model: Validation Quadratic Weighted Kappa')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('QWK Score')
    ax2.legend()
    ax2.grid(True)
    
    ax3.plot(history['val_accuracies'], label='Validation Accuracy', color='purple')
    ax3.set_title('SE-ResNeXt26 YCbCr Model: Validation Accuracy')
    ax3.set_xlabel('Epoch')
    ax3.set_ylabel('Accuracy (%)')
    ax3.legend()
    ax3.grid(True)
    
    ax4.plot(history['learning_rates'], label='Learning Rate', color='brown')
    ax4.set_title('SE-ResNeXt26 YCbCr Model: Learning Rate Schedule')
    ax4.set_xlabel('Epoch')
    ax4.set_ylabel('Learning Rate')
    ax4.set_yscale('log')
    ax4.legend()
    ax4.grid(True)
    
    plt.tight_layout()
    plt.savefig('seresnext26_ycbcr_training_history.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"\n{'='*70}")
    print("SE-RESNEXT26 YCBCR MODEL TRAINING RESULTS")
    print(f"{'='*70}")
    print(f"Best QWK Score: {history['best_kappa']:.4f}")
    print(f"Total Epochs: {history['total_epochs']}")
    print(f"Final Validation Accuracy: {history['val_accuracies'][-1]:.2f}%")
    
    if history['best_kappa'] > 0.889:
        print("✅ Target QWK score (>0.889) achieved!")
    else:
        print("❌ Target QWK score (>0.889) not yet achieved.")
        print(f"   Gap to target: {0.889 - history['best_kappa']:.4f}")

def main():
    """
    Main training pipeline for SE-ResNeXt26 YCbCr classification
    """
    config = {
        'train_csv': '/kaggle/input/aptos2019-blindness-detection/train.csv',
        'test_csv': '/kaggle/input/aptos2019-blindness-detection/test.csv',
        'train_img_dir': '/kaggle/input/aptos2019-blindness-detection/train_images',
        'test_img_dir': '/kaggle/input/aptos2019-blindness-detection/test_images',
        'batch_size': 16,
        'num_epochs': 40,
        'learning_rate': 1e-4,
        'num_classes': 5,
        'cardinality': 32,
        'base_width': 4
    }
    
    print("="*70)
    print("DIABETIC RETINOPATHY YCbCr SE-RESNEXT26 MODEL")
    print("="*70)
    print("Configuration:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    print("="*70)
    
    # Get transforms
    train_transforms, val_transforms = get_ycbcr_transforms()
    
    # Load data
    print("\nLoading YCbCr training data...")
    full_train_dataset = DiabeticRetinopathyYCbCrDataset(
        csv_file=config['train_csv'],
        img_dir=config['train_img_dir'],
        transform=train_transforms
    )
    
    train_size = int(0.8 * len(full_train_dataset))
    val_size = len(full_train_dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_train_dataset, [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config['batch_size'], 
        shuffle=True, 
        num_workers=4,
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=4,
        pin_memory=True
    )
    
    test_dataset = DiabeticRetinopathyYCbCrDataset(
        csv_file=config['test_csv'],
        img_dir=config['test_img_dir'],
        transform=val_transforms,
        is_test=True
    )
    test_loader = DataLoader(
        test_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=4,
        pin_memory=True
    )
    
    # Initialize model
    print("\nInitializing SE-ResNeXt26 model...")
    model = SEResNeXt26(
        num_classes=config['num_classes'],
        cardinality=config['cardinality'],
        base_width=config['base_width']
    )
    model.to(device)
    
    # Print model info
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    
    # Train model
    print("\nStarting SE-ResNeXt26 model training...")
    model, history = train_model(
        model, 
        train_loader, 
        val_loader, 
        num_epochs=config['num_epochs'],
        learning_rate=config['learning_rate']
    )
    
    # Plot history
    plot_training_history(history)
    
    # Validation analysis
    print("\nPerforming detailed validation analysis...")
    final_qwk, cm, report = validate_with_confusion_matrix(model, val_loader)
    
    # Generate predictions
    print("\nGenerating test predictions...")
    predictions, image_names = evaluate_model(model, test_loader)
    
    # Compile results
    results = {
        'experiment': 'SE-ResNeXt26 YCbCr Model',
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'best_qwk': float(history['best_kappa']),
        'final_validation_qwk': float(final_qwk),
        'total_epochs': int(history['total_epochs']),
        'model_architecture': 'SE-ResNeXt26 (26×4d)',
        'cardinality': config['cardinality'],
        'base_width': config['base_width'],
        'input_type': 'YCbCr (3-channel: Y, Cb, Cr)',
        'image_size': '512x512',
        'batch_size': config['batch_size'],
        'learning_rate': config['learning_rate'],
        'target_achieved': bool(history['best_kappa'] > 0.889),
        'model_advantages': [
            'ResNeXt architecture with grouped convolutions',
            'Squeeze-and-Excitation blocks for channel-wise attention',
            'Efficient parameter usage with cardinality=32',
            'Strong feature extraction capabilities for medical images'
        ]
    }
    
    # Save results
    with open('seresnext26_ycbcr_experiment_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    # Print summary
    print("\n" + "="*70)
    print("SE-RESNEXT26 YCBCR MODEL - FINAL RESULTS SUMMARY")
    print("="*70)
    for key, value in results.items():
        if key != 'model_advantages':
            print(f"{key}: {value}")
    print("\nModel Advantages:")
    for advantage in results['model_advantages']:
        print(f"  • {advantage}")
    print("="*70)
    
    print(f"\nFiles saved:")
    print(f"  - Model weights: 'best_seresnext26_ycbcr_model.pth'")
    print(f"  - Predictions: 'seresnext26_ycbcr_predictions.csv'")
    print(f"  - Training plots: 'seresnext26_ycbcr_training_history.png'")
    print(f"  - Confusion matrix: 'seresnext26_ycbcr_confusion_matrix.png'")
    print(f"  - Results: 'seresnext26_ycbcr_experiment_results.json'")
    
    return model, history, results

if __name__ == "__main__":
    # Set random seeds for reproducibility
    torch.manual_seed(42)
    np.random.seed(42)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    # Run SE-ResNeXt26 experiment
    model, history, results = main()
