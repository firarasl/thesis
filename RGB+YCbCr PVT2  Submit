import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import os
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Install and import timm
try:
    import timm
    print("timm imported successfully")
except ImportError:
    print("Installing timm...")
    import subprocess
    import sys
    subprocess.run([sys.executable, '-m', 'pip', 'install', 'timm'])
    import timm
    print("timm installed and imported successfully")

def crop_black_background(image, threshold=10):
    """
    Crop black background from retinal images
    """
    # Convert to grayscale for processing
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image
    
    # Create mask for non-black pixels
    mask = gray > threshold
    
    # Find bounding box of non-black region
    coords = np.argwhere(mask)
    if len(coords) == 0:
        return image  # Return original if no non-black pixels found
    
    y0, x0 = coords.min(axis=0)
    y1, x1 = coords.max(axis=0) + 1
    
    # Crop the image
    cropped = image[y0:y1, x0:x1]
    
    return cropped

class DiabeticRetinopathyRGBYCbCrDataset(Dataset):
    """
    Enhanced Dataset for Diabetic Retinopathy with RGB + YCbCr fusion
    """
    def __init__(self, csv_file, img_dir, transform=None, is_test=False, image_size=384):
        """
        Args:
            csv_file (string): Path to csv with image names
            img_dir (string): Directory with all images
            transform (callable, optional): Transform to be applied on images
            is_test (bool): Whether this is test dataset (no labels)
            image_size (int): Target image size (384x384)
        """
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test
        self.image_size = image_size
        
        print(f"Test dataset loaded: {len(self.data)} images")
        
    def __len__(self):
        return len(self.data)
    
    def preprocess_image(self, image_path):
        """
        Enhanced preprocessing with black background cropping
        """
        # Load image
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Could not load image: {image_path}")
        
        # Convert BGR to RGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Crop black background
        image = crop_black_background(image, threshold=10)
        
        # Resize to target size
        image = cv2.resize(image, (self.image_size, self.image_size))
        
        return image
    
    def rgb_to_ycbcr_tensor(self, rgb_image):
        """
        Convert RGB image to YCbCr
        """
        # Convert RGB to YCbCr using cv2
        ycbcr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2YCrCb)
        return ycbcr_image
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        # Get image name
        img_name = self.data.iloc[idx, 0]
        
        # Try different extensions
        img_extensions = ['.jpeg', '.jpg', '.png']
        img_path = None
        
        for ext in img_extensions:
            potential_path = os.path.join(self.img_dir, f"{img_name}{ext}")
            if os.path.exists(potential_path):
                img_path = potential_path
                break
                
        if img_path is None:
            raise FileNotFoundError(f"Image {img_name} not found with any extension")
        
        # Load and preprocess image
        rgb_image = self.preprocess_image(img_path)
        
        # Convert to YCbCr
        ycbcr_image = self.rgb_to_ycbcr_tensor(rgb_image)
        
        # Convert to tensors
        rgb_tensor = torch.from_numpy(rgb_image.transpose(2, 0, 1)).float() / 255.0
        ycbcr_tensor = torch.from_numpy(ycbcr_image.transpose(2, 0, 1)).float() / 255.0
        
        # Normalize both with ImageNet stats
        rgb_tensor = transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        )(rgb_tensor)
        
        ycbcr_tensor = transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        )(ycbcr_tensor)
        
        return (rgb_tensor, ycbcr_tensor), img_name

class PVTv2Backbone(nn.Module):
    """
    PVTv2 backbone wrapper for feature extraction
    """
    def __init__(self, model_name='pvt_v2_b2', pretrained=False):
        super(PVTv2Backbone, self).__init__()
        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0)
        self.feature_dim = self.model.num_features
        
    def forward(self, x):
        return self.model(x)

class EnhancedDualStreamFusionPVT(nn.Module):
    """
    Enhanced fusion with attention mechanism using PVTv2 backbones
    """
    def __init__(self, num_classes=5, dropout_rate=0.5):
        super(EnhancedDualStreamFusionPVT, self).__init__()
        
        # RGB stream with PVTv2
        self.rgb_backbone = PVTv2Backbone(model_name='pvt_v2_b2', pretrained=False)
        
        # YCbCr stream with PVTv2
        self.ycbcr_backbone = PVTv2Backbone(model_name='pvt_v2_b2', pretrained=False)
        
        # Get feature dimensions from PVTv2-b2
        rgb_features = 512  # PVTv2-b2 feature dimension
        ycbcr_features = 512
        
        # Attention mechanism for feature fusion
        self.attention = nn.Sequential(
            nn.Linear(rgb_features + ycbcr_features, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 2),
            nn.Softmax(dim=1)
        )
        
        # Final classifier
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(rgb_features + ycbcr_features, 1024),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(1024),
            nn.Dropout(dropout_rate/2),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(512),
            nn.Dropout(dropout_rate/2),
            nn.Linear(512, num_classes)
        )
        
    def forward(self, x):
        rgb, ycbcr = x
        
        rgb_features = self.rgb_backbone(rgb)
        ycbcr_features = self.ycbcr_backbone(ycbcr)
        
        # Concatenate features
        combined = torch.cat([rgb_features, ycbcr_features], dim=1)
        
        # Calculate attention weights
        attention_weights = self.attention(combined)
        
        # Apply attention
        weighted_rgb = attention_weights[:, 0:1] * rgb_features
        weighted_ycbcr = attention_weights[:, 1:2] * ycbcr_features
        
        # Final fusion
        fused_features = torch.cat([weighted_rgb, weighted_ycbcr], dim=1)
        
        return self.classifier(fused_features)

def load_trained_model(model_path, num_classes=5, dropout_rate=0.5):
    """
    Load the pre-trained RGB+YCbCr fusion model
    """
    print(f"Loading model from: {model_path}")
    
    # Initialize model architecture WITHOUT downloading pretrained weights
    model = EnhancedDualStreamFusionPVT(
        num_classes=num_classes, 
        dropout_rate=dropout_rate
    )
    
    # Load trained weights
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint)
    
    model.to(device)
    model.eval()
    
    print("Model loaded successfully!")
    return model

def generate_predictions(model, test_loader, use_tta=False):
    """
    Generate predictions for test set
    
    Args:
        model: Trained model
        test_loader: DataLoader for test set
        use_tta: Whether to use Test Time Augmentation (TTA)
    """
    model.eval()
    predictions = []
    image_names = []
    all_probabilities = []
    
    print("Generating predictions...")
    
    with torch.no_grad():
        for data, names in tqdm(test_loader, desc="Processing test images"):
            # data is a tuple of (rgb_tensor, ycbcr_tensor)
            rgb_data, ycbcr_data = data
            rgb_data = rgb_data.to(device)
            ycbcr_data = ycbcr_data.to(device)
            
            if use_tta:
                # Test Time Augmentation for dual-stream model
                outputs = model((rgb_data, ycbcr_data))
                
                # Horizontal flip
                outputs += model((torch.flip(rgb_data, dims=[3]), torch.flip(ycbcr_data, dims=[3])))
                
                # Vertical flip
                outputs += model((torch.flip(rgb_data, dims=[2]), torch.flip(ycbcr_data, dims=[2])))
                
                # Average the predictions
                outputs = outputs / 3.0
            else:
                outputs = model((rgb_data, ycbcr_data))
            
            # Convert logits to probabilities
            probs = torch.softmax(outputs, dim=1)
            
            # Get predicted classes
            preds = probs.argmax(dim=1)
            
            predictions.extend(preds.cpu().numpy())
            image_names.extend(names)
            all_probabilities.extend(probs.cpu().numpy())
    
    return predictions, image_names, np.array(all_probabilities)

def create_submission_file(predictions, image_names, output_file='submission.csv'):
    """
    Create submission file in Kaggle format
    """
    submission_df = pd.DataFrame({
        'id_code': image_names,
        'diagnosis': predictions
    })
    
    # Sort by id_code to ensure consistent ordering
    submission_df = submission_df.sort_values('id_code')
    
    # Save to CSV
    submission_df.to_csv(output_file, index=False)
    
    print(f"Submission file saved: {output_file}")
    print(f"Total predictions: {len(submission_df)}")
    
    # Print prediction distribution
    print("\nPrediction distribution:")
    label_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative']
    for i, label in enumerate(label_names):
        count = (submission_df['diagnosis'] == i).sum()
        percentage = count / len(submission_df) * 100
        print(f"  Class {i} ({label}): {count} images ({percentage:.1f}%)")
    
    return submission_df

def main():
    """
    Main inference pipeline for RGB+YCbCr fusion model
    """
    # Configuration
    config = {
        'model_path': '/kaggle/input/rgb-ycbcr-final-pvtv2-training/best_dual_stream_pvt_model.pth',  # Update with your model path
        'test_csv': '/kaggle/input/aptos2019-blindness-detection/test.csv',
        'test_img_dir': '/kaggle/input/aptos2019-blindness-detection/test_images',
        'batch_size': 8,  # Smaller batch size for transformer inference
        'num_classes': 5,
        'dropout_rate': 0.5,
        'use_tta': True,  # Use Test Time Augmentation for better results
        'output_file': 'submission.csv',  # Different filename
        'image_size': 384  # PVTv2 uses 384x384
    }
    
    print("="*70)
    print("DIABETIC RETINOPATHY RGB+YCbCr FUSION MODEL - INFERENCE")
    print("="*70)
    print("Configuration:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    print("="*70)
    
    # Check if test files exist
    if not os.path.exists(config['test_csv']):
        print(f"Error: Test CSV file not found at {config['test_csv']}")
        return
    
    if not os.path.exists(config['test_img_dir']):
        print(f"Error: Test images directory not found at {config['test_img_dir']}")
        return
    
    if not os.path.exists(config['model_path']):
        print(f"Error: Model file not found at {config['model_path']}")
        print("Please make sure the model file exists or update the model_path in the config.")
        return
    
    # Load trained model
    model = load_trained_model(
        config['model_path'], 
        config['num_classes'], 
        config['dropout_rate']
    )
    
    # Load test dataset
    print("\nLoading test data...")
    test_dataset = DiabeticRetinopathyRGBYCbCrDataset(
        csv_file=config['test_csv'],
        img_dir=config['test_img_dir'],
        transform=None,  # No transforms needed as we handle preprocessing in dataset
        is_test=True,
        image_size=config['image_size']
    )
    
    # Create test data loader
    test_loader = DataLoader(
        test_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=2,
        pin_memory=True
    )
    
    # Generate predictions
    print(f"\nGenerating predictions with TTA: {config['use_tta']}")
    predictions, image_names, probabilities = generate_predictions(
        model, 
        test_loader, 
        use_tta=config['use_tta']
    )
    
    # Create submission file
    print("\nCreating submission file...")
    submission_df = create_submission_file(
        predictions, 
        image_names, 
        config['output_file']
    )
    
    print("\n" + "="*70)
    print("INFERENCE COMPLETED SUCCESSFULLY!")
    print("="*70)
    print(f"Submission file: {config['output_file']}")
    print(f"Total test images processed: {len(predictions)}")
    print("="*70)
    
    return submission_df

if __name__ == "__main__":
    # Set random seeds for reproducibility
    torch.manual_seed(42)
    np.random.seed(42)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    # Run inference
    submission_df = main()
