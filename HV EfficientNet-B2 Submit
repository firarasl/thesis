import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision import models
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import os
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class DiabeticRetinopathyHVDataset(Dataset):
    """
    Custom Dataset for Diabetic Retinopathy with HV (Hue-Value) channels (Test Dataset)
    """
    def __init__(self, csv_file, img_dir, transform=None):
        """
        Args:
            csv_file (string): Path to csv with image names
            img_dir (string): Directory with all images
            transform (callable, optional): Transform to be applied on images
        """
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        
        print(f"HV Test dataset loaded: {len(self.data)} images")
        
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        # Get image name (assuming the CSV has 'id_code' column)
        img_name = self.data.iloc[idx, 0]  # First column should be image ID
        
        # Try different extensions
        img_extensions = ['.png', '.jpg', '.jpeg']
        img_path = None
        
        for ext in img_extensions:
            potential_path = os.path.join(self.img_dir, f"{img_name}{ext}")
            if os.path.exists(potential_path):
                img_path = potential_path
                break
                
        if img_path is None:
            raise FileNotFoundError(f"Image {img_name} not found with any extension")
        
        # Load image
        image = cv2.imread(img_path)
        if image is None:
            raise ValueError(f"Could not load image: {img_path}")
        
        # Convert BGR to RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Convert RGB to HSV
        image_hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)
        
        # Extract Hue and Value channels (H and V)
        image_hv = image_hsv[:, :, [0, 2]]  # H, V channels
        
        # Convert to PIL Image for transforms
        image_pil = Image.fromarray(image_hv.astype('uint8'))
        
        if self.transform:
            image_pil = self.transform(image_pil)
            
        return image_pil, img_name

class DREfficientNetB2HVClassifier(nn.Module):
    """
    Diabetic Retinopathy Classifier using EfficientNet-B2 for HV (Hue-Value) channels
    """
    def __init__(self, num_classes=5, pretrained=False, dropout_rate=0.4):
        super(DREfficientNetB2HVClassifier, self).__init__()
        
        # Use EfficientNet-B2 as backbone
        self.backbone = models.efficientnet_b2(pretrained=pretrained)
        
        # Store original first conv layer for weight adaptation
        original_conv = self.backbone.features[0][0]
        
        # Modify first conv layer for 2 input channels (HV)
        self.backbone.features[0][0] = nn.Conv2d(
            2, original_conv.out_channels, 
            kernel_size=original_conv.kernel_size,
            stride=original_conv.stride,
            padding=original_conv.padding,
            bias=original_conv.bias is not None
        )
        
        # Initialize new conv1 weights (no pretrained weights needed for inference)
        if pretrained:
            with torch.no_grad():
                # Average pretrained RGB weights for HV channels initialization
                rgb_weights = original_conv.weight
                avg_weights = rgb_weights.mean(dim=1, keepdim=True)
                self.backbone.features[0][0].weight = nn.Parameter(
                    torch.cat([avg_weights, avg_weights], dim=1)
                )
                
                if original_conv.bias is not None:
                    self.backbone.features[0][0].bias = nn.Parameter(original_conv.bias.clone())
        
        # Get the number of features in the classifier
        num_features = self.backbone.classifier[1].in_features
        
        # Replace final layer with custom classifier
        self.backbone.classifier = nn.Sequential(
            nn.Dropout(p=dropout_rate),
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(p=dropout_rate/2),
            nn.Linear(512, num_classes)
        )
        
    def forward(self, x):
        return self.backbone(x)

def get_hv_test_transforms():
    """
    Define preprocessing transforms for HV test images (no augmentation)
    """
    # Two-channel normalization for HV channels (same as training)
    mean = [0.5, 0.5]  # H, V channel means
    std = [0.3, 0.3]   # H, V channel stds
    
    test_transforms = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean, std=std)
    ])
    
    return test_transforms

def load_trained_hv_model(model_path, num_classes=5, dropout_rate=0.4):
    """
    Load the pre-trained HV EfficientNet-B2 model
    """
    print(f"Loading HV EfficientNet-B2 model from: {model_path}")
    
    # Initialize model architecture WITHOUT downloading pretrained weights
    model = DREfficientNetB2HVClassifier(
        num_classes=num_classes, 
        dropout_rate=dropout_rate, 
        pretrained=False  # No need for ImageNet weights during inference
    )
    
    # Load trained weights
    checkpoint = torch.load(model_path, map_location=device)
    
    # Handle both state_dict and full model save formats
    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
        model.load_state_dict(checkpoint['state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model.to(device)
    model.eval()
    
    print("HV EfficientNet-B2 model loaded successfully!")
    
    # Print model info
    total_params = sum(p.numel() for p in model.parameters())
    print(f"Model parameters: {total_params:,}")
    
    return model

def generate_hv_predictions(model, test_loader, use_tta=False):
    """
    Generate predictions for test set using HV model
    
    Args:
        model: Trained HV model
        test_loader: DataLoader for test set
        use_tta: Whether to use Test Time Augmentation (TTA)
    """
    model.eval()
    predictions = []
    image_names = []
    all_probabilities = []
    
    print("Generating HV predictions...")
    
    with torch.no_grad():
        for data, names in tqdm(test_loader, desc="Processing HV test images"):
            data = data.to(device)
            
            if use_tta:
                # Test Time Augmentation for HV model
                outputs = model(data)
                
                # Horizontal flip
                data_hflip = torch.flip(data, dims=[3])
                outputs += model(data_hflip)
                
                # Vertical flip
                data_vflip = torch.flip(data, dims=[2])
                outputs += model(data_vflip)
                
                # Average the predictions
                outputs = outputs / 3.0
            else:
                outputs = model(data)
            
            # Convert logits to probabilities
            probs = torch.softmax(outputs, dim=1)
            
            # Get predicted classes
            preds = probs.argmax(dim=1)
            
            predictions.extend(preds.cpu().numpy())
            image_names.extend(names)
            all_probabilities.extend(probs.cpu().numpy())
    
    return predictions, image_names, np.array(all_probabilities)

def create_submission_file(predictions, image_names, output_file='hv_effnet_submission.csv'):
    """
    Create submission file in Kaggle format
    """
    submission_df = pd.DataFrame({
        'id_code': image_names,
        'diagnosis': predictions
    })
    
    # Sort by id_code to ensure consistent ordering
    submission_df = submission_df.sort_values('id_code')
    
    # Save to CSV
    submission_df.to_csv(output_file, index=False)
    
    print(f"HV Submission file saved: {output_file}")
    print(f"Total predictions: {len(submission_df)}")
    
    # Print prediction distribution
    print("\nHV Model Prediction distribution:")
    label_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative']
    for i, label in enumerate(label_names):
        count = (submission_df['diagnosis'] == i).sum()
        percentage = count / len(submission_df) * 100
        print(f"  Class {i} ({label}): {count} images ({percentage:.1f}%)")
    
    return submission_df

def save_probability_analysis(predictions, probabilities, image_names, output_file='hv_effnet_probabilities.csv'):
    """
    Save probability analysis for debugging and analysis
    """
    prob_df = pd.DataFrame(probabilities, columns=[f'class_{i}_prob' for i in range(5)])
    prob_df['id_code'] = image_names
    prob_df['prediction'] = predictions
    
    # Calculate confidence scores (max probability)
    prob_df['confidence'] = np.max(probabilities, axis=1)
    
    # Reorder columns
    cols = ['id_code', 'prediction', 'confidence'] + [f'class_{i}_prob' for i in range(5)]
    prob_df = prob_df[cols]
    
    prob_df.to_csv(output_file, index=False)
    print(f"Probability analysis saved: {output_file}")
    
    return prob_df

def main():
    """
    Main inference pipeline for HV EfficientNet-B2 model
    """
    # Configuration
    config = {
        'model_path': '/kaggle/input/hv-efficientnetb2-training/best_hv_effnet_model.pth',  # Update with your HV model path
        'test_csv': '/kaggle/input/aptos2019-blindness-detection/test.csv',
        'test_img_dir': '/kaggle/input/aptos2019-blindness-detection/test_images',
        'batch_size': 32,
        'num_classes': 5,
        'dropout_rate': 0.4,
        'use_tta': True,
        'output_file': 'submission.csv',
        'save_probabilities': True
    }
    
    print("="*70)
    print("DIABETIC RETINOPATHY HV EFFICIENTNET-B2 MODEL - INFERENCE")
    print("="*70)
    print("Configuration:")
    print(f"  Model: HV EfficientNet-B2 (2-channel Hue-Value)")
    print(f"  Input channels: 2 (Hue + Value from HSV)")
    print(f"  Image size: 512x512")
    print(f"  TTA: {config['use_tta']}")
    for key, value in config.items():
        if key not in ['model_path', 'test_csv', 'test_img_dir']:
            print(f"  {key}: {value}")
    print("="*70)
    
    # Check if test files exist
    if not os.path.exists(config['test_csv']):
        print(f"Error: Test CSV file not found at {config['test_csv']}")
        return
    
    if not os.path.exists(config['test_img_dir']):
        print(f"Error: Test images directory not found at {config['test_img_dir']}")
        return
    
    if not os.path.exists(config['model_path']):
        print(f"Error: HV Model file not found at {config['model_path']}")
        print("Please make sure the model file exists or update the model_path in the config.")
        print("Expected file: best_hv_effnet_model.pth")
        return
    
    # Load trained HV model
    model = load_trained_hv_model(
        config['model_path'], 
        config['num_classes'], 
        config['dropout_rate']
    )
    
    # Get HV test transforms
    test_transforms = get_hv_test_transforms()
    
    # Load test dataset with HV preprocessing
    print("\nLoading HV test data...")
    test_dataset = DiabeticRetinopathyHVDataset(
        csv_file=config['test_csv'],
        img_dir=config['test_img_dir'],
        transform=test_transforms
    )
    
    # Create test data loader
    test_loader = DataLoader(
        test_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=4,
        pin_memory=True
    )
    
    # Generate predictions
    print(f"\nGenerating HV predictions with TTA: {config['use_tta']}")
    predictions, image_names, probabilities = generate_hv_predictions(
        model, 
        test_loader, 
        use_tta=config['use_tta']
    )
    
    # Create submission file
    print("\nCreating HV submission file...")
    submission_df = create_submission_file(
        predictions, 
        image_names, 
        config['output_file']
    )
    
    # Save probability analysis if requested
    if config['save_probabilities']:
        print("\nSaving probability analysis...")
        prob_df = save_probability_analysis(
            predictions, 
            probabilities, 
            image_names,
            'hv_effnet_probabilities.csv'
        )
    
    print("\n" + "="*70)
    print("HV EFFICIENTNET-B2 INFERENCE COMPLETED SUCCESSFULLY!")
    print("="*70)
    print(f"Submission file: {config['output_file']}")
    print(f"Total test images processed: {len(predictions)}")
    print(f"Input type: 2-channel HV (Hue-Value)")
    print(f"Model: EfficientNet-B2 adapted for HV channels")
    print("="*70)
    
    return submission_df

if __name__ == "__main__":
    # Set random seeds for reproducibility
    torch.manual_seed(42)
    np.random.seed(42)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    # Run inference
    submission_df = main()
