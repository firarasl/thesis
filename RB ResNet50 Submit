import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import os
from torch.utils.data import Dataset, DataLoader
from torchvision import models
from tqdm import tqdm
import json
import warnings
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class DiabeticRetinopathyRBDataset(Dataset):
    """
    Custom Dataset for Diabetic Retinopathy with RB (Red-Blue) channels only - Test Version
    """
    def __init__(self, csv_file, img_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        
        print(f"Test dataset loaded: {len(self.data)} images")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        # Get image name
        img_name = str(self.data.iloc[idx, 0])
        
        # Try different extensions
        img_path = None
        for ext in ['.png', '.jpeg', '.jpg']:
            potential_path = os.path.join(self.img_dir, f"{img_name}{ext}")
            if os.path.exists(potential_path):
                img_path = potential_path
                break
                
        if img_path is None:
            print(f"Warning: Image {img_name} not found with any extension")
            # Return dummy tensor if image not found
            return torch.zeros((2, 512, 512), dtype=torch.float32), img_name
        
        try:
            # Load image
            image = cv2.imread(img_path)
            if image is None:
                print(f"Warning: Could not load image: {img_path}")
                return torch.zeros((2, 512, 512), dtype=torch.float32), img_name
            
            # Convert BGR to RGB
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Extract Red and Blue channels only
            image_rb = np.zeros((image_rgb.shape[0], image_rgb.shape[1], 2), dtype=np.uint8)
            image_rb[:, :, 0] = image_rgb[:, :, 0]  # Red channel
            image_rb[:, :, 1] = image_rgb[:, :, 2]  # Blue channel
            
            # Convert to tensor
            image_tensor = torch.from_numpy(image_rb).permute(2, 0, 1).float() / 255.0
            
            if self.transform:
                image_tensor = self.transform(image_tensor)
                
        except Exception as e:
            print(f"Error loading image {img_name}: {e}")
            return torch.zeros((2, 512, 512), dtype=torch.float32), img_name
            
        return image_tensor, img_name

class RBTransforms:
    """
    Custom transforms for RB (2-channel) images - Inference Version
    """
    def __init__(self, size=(512, 512), mean=None, std=None):
        self.size = size
        self.mean = mean or [0.5, 0.5]
        self.std = std or [0.5, 0.5]
        
    def __call__(self, tensor):
        # tensor shape: (2, H, W)
        
        # Resize
        tensor = torch.nn.functional.interpolate(
            tensor.unsqueeze(0), 
            size=self.size, 
            mode='bilinear', 
            align_corners=False
        ).squeeze(0)
        
        # Normalize
        for i in range(2):
            tensor[i] = (tensor[i] - self.mean[i]) / self.std[i]
            
        return tensor

class DRRBChannelClassifier(nn.Module):
    """
    Diabetic Retinopathy Classifier for RB (Red-Blue) channels
    """
    def __init__(self, num_classes=5, pretrained=True, dropout_rate=0.5):
        super(DRRBChannelClassifier, self).__init__()
        
        # Use ResNet50 as backbone
        self.backbone = models.resnet50(pretrained=pretrained)
        
        # Modify first conv layer for 2 input channels (RB)
        original_conv1 = self.backbone.conv1
        
        # Create new conv1 layer with 2 input channels
        self.backbone.conv1 = nn.Conv2d(
            2, 64, kernel_size=7, stride=2, padding=3, bias=False
        )
        
        # Store original fc layer input features
        num_features = self.backbone.fc.in_features
        
        # Replace final layer with custom classifier
        self.backbone.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(num_features, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate/2),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate/4),
            nn.Linear(256, num_classes)
        )
        
    def forward(self, x):
        return self.backbone(x)

def load_model_and_stats(model_path, stats_path=None):
    """
    Load the trained model and normalization statistics
    """
    print(f"Loading model from: {model_path}")
    
    # Load checkpoint
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    # Initialize model
    model = DRRBChannelClassifier(num_classes=5, pretrained=False, dropout_rate=0.5)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    
    print(f"Model loaded successfully!")
    print(f"Best QWK from training: {checkpoint.get('best_kappa', 'N/A')}")
    print(f"Training epoch: {checkpoint.get('epoch', 'N/A')}")
    
    # Load normalization statistics
    rb_mean, rb_std = [0.5, 0.5], [0.5, 0.5]  # defaults
    
    if stats_path and os.path.exists(stats_path):
        try:
            with open(stats_path, 'r') as f:
                stats = json.load(f)
                rb_mean = stats.get('rb_mean', rb_mean)
                rb_std = stats.get('rb_std', rb_std)
            print(f"Loaded normalization stats: mean={rb_mean}, std={rb_std}")
        except Exception as e:
            print(f"Warning: Could not load stats from {stats_path}: {e}")
            print("Using default normalization values")
    else:
        print("Using default normalization values")
    
    return model, rb_mean, rb_std

def create_test_dataloader(test_csv, test_img_dir, rb_mean, rb_std, batch_size=32):
    """
    Create test data loader
    """
    # Create transform for test data
    test_transform = RBTransforms(
        size=(512, 512), 
        mean=rb_mean, 
        std=rb_std
    )
    
    # Create test dataset
    test_dataset = DiabeticRetinopathyRBDataset(
        test_csv, 
        test_img_dir, 
        test_transform
    )
    
    # Create test data loader
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=2, 
        pin_memory=True
    )
    
    print(f"Test loader created: {len(test_loader)} batches")
    return test_loader

def predict_test_set(model, test_loader, use_tta=True):
    """
    Make predictions on test set with optional Test Time Augmentation
    """
    model.eval()
    predictions = []
    image_names = []
    
    print("Making predictions on test set...")
    
    with torch.no_grad():
        for batch_idx, (data, names) in enumerate(tqdm(test_loader, desc="Predicting")):
            data = data.to(device)
            
            if use_tta:
                # Test Time Augmentation - horizontal flip
                outputs_orig = model(data)
                outputs_flip = model(torch.flip(data, [-1]))  # horizontal flip
                
                # Average the predictions
                outputs = (outputs_orig + outputs_flip) / 2
            else:
                outputs = model(data)
            
            # Get probabilities and predicted classes
            probs = torch.softmax(outputs, dim=1)
            preds = torch.argmax(probs, dim=1)
            
            predictions.extend(preds.cpu().numpy())
            image_names.extend(names)
            
            if batch_idx % 50 == 0:
                print(f"Processed {batch_idx * len(data)} images...")
    
    return predictions, image_names

def create_submission_csv(predictions, image_names, output_file='submission.csv'):
    """
    Create submission CSV file
    """
    # Create submission dataframe
    submission_df = pd.DataFrame({
        'id_code': image_names,
        'diagnosis': predictions
    })
    
    # Sort by id_code to match expected format
    submission_df = submission_df.sort_values('id_code').reset_index(drop=True)
    
    # Save submission file
    submission_df.to_csv(output_file, index=False)
    
    print(f"\nSubmission file created: {output_file}")
    print(f"Number of predictions: {len(submission_df)}")
    
    # Show class distribution
    class_counts = submission_df['diagnosis'].value_counts().sort_index()
    print("\nPredicted class distribution:")
    for class_idx, count in class_counts.items():
        percentage = count / len(submission_df) * 100
        print(f"  Class {class_idx}: {count} images ({percentage:.1f}%)")
    
    return submission_df

def main():
    """
    Main inference function
    """
    # Configuration - Update these paths according to your setup
    config = {
        'model_path': '/kaggle/input/diabetic-retinopathy-rb/best_rb_model.pth',
        'stats_path': '/kaggle/input/diabetic-retinopathy-rb/rb_normalization_stats.json',  # Optional: if you have this file
        'test_csv': '/kaggle/input/aptos2019-blindness-detection/test.csv',
        'test_img_dir': '/kaggle/input/aptos2019-blindness-detection/test_images',
        'batch_size': 32,
        'use_tta': True,  # Test Time Augmentation
        'output_file': 'submission.csv'
    }
    
    print("="*70)
    print("DIABETIC RETINOPATHY RB MODEL INFERENCE")
    print("="*70)
    
    # Check if files exist
    if not os.path.exists(config['model_path']):
        print(f"Error: Model file not found at {config['model_path']}")
        return None
    
    if not os.path.exists(config['test_csv']):
        print(f"Error: Test CSV file not found at {config['test_csv']}")
        return None
    
    if not os.path.exists(config['test_img_dir']):
        print(f"Error: Test images directory not found at {config['test_img_dir']}")
        return None
    
    # Load model and normalization statistics
    model, rb_mean, rb_std = load_model_and_stats(
        config['model_path'], 
        config['stats_path']
    )
    
    # Create test data loader
    test_loader = create_test_dataloader(
        config['test_csv'],
        config['test_img_dir'],
        rb_mean,
        rb_std,
        config['batch_size']
    )
    
    # Make predictions
    predictions, image_names = predict_test_set(
        model, 
        test_loader, 
        use_tta=config['use_tta']
    )
    
    # Create submission file
    submission_df = create_submission_csv(
        predictions, 
        image_names, 
        config['output_file']
    )
    
    print(f"\n{'='*70}")
    print("INFERENCE COMPLETED SUCCESSFULLY")
    print(f"{'='*70}")
    print(f"Submission file: {config['output_file']}")
    print(f"Total predictions: {len(predictions)}")
    print(f"Test Time Augmentation: {'Enabled' if config['use_tta'] else 'Disabled'}")
    
    # Show first few predictions
    print(f"\nFirst 10 predictions:")
    for i in range(min(10, len(submission_df))):
        print(f"  {submission_df.iloc[i]['id_code']}: Class {submission_df.iloc[i]['diagnosis']}")
    
    return submission_df

if __name__ == "__main__":
    submission = main()
    if submission is not None:
        print("\nüéâ Inference completed successfully!")
        print("Your submission.csv file is ready for upload!")
    else:
        print("\n‚ùå Inference failed. Please check the error messages above.")
