import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import cv2
import os
from tqdm import tqdm
import json
from torchvision import models
import warnings
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class DRRGChannelClassifier(nn.Module):
    """
    Diabetic Retinopathy Classifier for RG (Red-Green) channels
    """
    def __init__(self, num_classes=5, dropout_rate=0.5):
        super(DRRGChannelClassifier, self).__init__()
        
        # Use ResNet50 as backbone
        self.backbone = models.resnet50(pretrained=False)  # Set to False for inference
        
        # Modify first conv layer for 2 input channels (RG)
        self.backbone.conv1 = nn.Conv2d(
            2, 64, kernel_size=7, stride=2, padding=3, bias=False
        )
        
        # Store original fc layer input features
        num_features = self.backbone.fc.in_features
        
        # Replace final layer with custom classifier
        self.backbone.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(num_features, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate/2),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate/4),
            nn.Linear(256, num_classes)
        )
        
    def forward(self, x):
        return self.backbone(x)

class RGTransforms:
    """
    Custom transforms for RG (2-channel) images - Inference version
    """
    def __init__(self, size=(512, 512), mean=None, std=None):
        self.size = size
        self.mean = mean or [0.5, 0.5]
        self.std = std or [0.5, 0.5]
        
    def __call__(self, tensor):
        # tensor shape: (2, H, W)
        
        # Resize
        tensor = torch.nn.functional.interpolate(
            tensor.unsqueeze(0), 
            size=self.size, 
            mode='bilinear', 
            align_corners=False
        ).squeeze(0)
        
        # Normalize - Apply channel-specific normalization
        for i in range(2):
            tensor[i] = (tensor[i] - self.mean[i]) / self.std[i]
            
        return tensor

class DiabeticRetinopathyRGTestDataset(Dataset):
    """
    Test Dataset for Diabetic Retinopathy with RG (Red-Green) channels only
    """
    def __init__(self, csv_file, img_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        
        print(f"Test dataset loaded: {len(self.data)} images")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        # Get image name
        img_name = str(self.data.iloc[idx, 0])  # Assuming first column is image name
        
        # Try different extensions
        img_path = None
        for ext in ['.png', '.jpg', '.jpeg']:
            potential_path = os.path.join(self.img_dir, f"{img_name}{ext}")
            if os.path.exists(potential_path):
                img_path = potential_path
                break
                
        if img_path is None:
            print(f"Warning: Image {img_name} not found with any extension")
            # Return a dummy tensor
            image_tensor = torch.zeros((2, 512, 512), dtype=torch.float32)
            return image_tensor, img_name
        
        try:
            # Load image
            image = cv2.imread(img_path)
            if image is None:
                print(f"Warning: Could not load image: {img_path}")
                image_tensor = torch.zeros((2, 512, 512), dtype=torch.float32)
                return image_tensor, img_name
            
            # Convert BGR to RGB
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Extract Red and Green channels only
            image_rg = np.zeros((image_rgb.shape[0], image_rgb.shape[1], 2), dtype=np.uint8)
            image_rg[:, :, 0] = image_rgb[:, :, 0]  # Red channel
            image_rg[:, :, 1] = image_rgb[:, :, 1]  # Green channel
            
            # Convert to tensor format
            image_tensor = torch.from_numpy(image_rg).permute(2, 0, 1).float() / 255.0
            
            if self.transform:
                image_tensor = self.transform(image_tensor)
                
        except Exception as e:
            print(f"Error loading image {img_name}: {e}")
            # Return a dummy tensor in case of error
            image_tensor = torch.zeros((2, 512, 512), dtype=torch.float32)
            
        return image_tensor, img_name

def load_trained_model(model_path, num_classes=5, dropout_rate=0.5):
    """
    Load the trained RG channel model
    """
    print(f"Loading model from: {model_path}")
    
    # Initialize model
    model = DRRGChannelClassifier(num_classes=num_classes, dropout_rate=dropout_rate)
    
    # Load checkpoint (set weights_only=False for compatibility with older PyTorch versions)
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    # Load model state dict
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"Model loaded successfully!")
        if 'best_kappa' in checkpoint:
            print(f"Best QWK score during training: {checkpoint['best_kappa']:.4f}")
        if 'epoch' in checkpoint:
            print(f"Training stopped at epoch: {checkpoint['epoch'] + 1}")
    else:
        # If checkpoint contains only state dict
        model.load_state_dict(checkpoint)
        print("Model state dict loaded successfully!")
    
    model.to(device)
    model.eval()
    
    return model

def load_normalization_stats(stats_path=None):
    """
    Load RG normalization statistics
    """
    if stats_path and os.path.exists(stats_path):
        print(f"Loading normalization stats from: {stats_path}")
        with open(stats_path, 'r') as f:
            stats = json.load(f)
        rg_mean = stats['rg_mean']
        rg_std = stats['rg_std']
        print(f"Loaded RG normalization: mean={rg_mean}, std={rg_std}")
    else:
        print("Normalization stats file not found, using training values")
        # Your actual training normalization statistics
        rg_mean = [0.42165068235294123, 0.2244939843137255]
        rg_std = [0.2770468261611848, 0.14950096306753813]
        
        print("Using RG normalization statistics from your training:")
        print(f"  Red Channel - Mean: {rg_mean[0]:.4f}, Std: {rg_std[0]:.4f}")
        print(f"  Green Channel - Mean: {rg_mean[1]:.4f}, Std: {rg_std[1]:.4f}")
    
    return rg_mean, rg_std

def run_inference(model, test_loader, use_tta=True):
    """
    Run inference on test dataset
    
    Args:
        model: Trained model
        test_loader: Test data loader
        use_tta: Whether to use Test Time Augmentation
    """
    model.eval()
    predictions = []
    image_names = []
    
    print(f"Running inference on {len(test_loader.dataset)} test images...")
    print(f"Test Time Augmentation: {'Enabled' if use_tta else 'Disabled'}")
    
    with torch.no_grad():
        for batch_idx, (data, names) in enumerate(tqdm(test_loader, desc="Inference")):
            data = data.to(device)
            
            if use_tta:
                # Test Time Augmentation
                batch_preds = []
                
                # Original image
                outputs = model(data)
                batch_preds.append(torch.softmax(outputs, dim=1))
                
                # Horizontal flip
                data_hflip = torch.flip(data, [-1])
                outputs_hflip = model(data_hflip)
                batch_preds.append(torch.softmax(outputs_hflip, dim=1))
                
                # Vertical flip
                data_vflip = torch.flip(data, [-2])
                outputs_vflip = model(data_vflip)
                batch_preds.append(torch.softmax(outputs_vflip, dim=1))
                
                # Both flips
                data_hvflip = torch.flip(torch.flip(data, [-1]), [-2])
                outputs_hvflip = model(data_hvflip)
                batch_preds.append(torch.softmax(outputs_hvflip, dim=1))
                
                # Average predictions
                final_outputs = torch.stack(batch_preds).mean(dim=0)
            else:
                outputs = model(data)
                final_outputs = torch.softmax(outputs, dim=1)
            
            # Get predictions
            preds = final_outputs.argmax(dim=1)
            predictions.extend(preds.cpu().numpy())
            image_names.extend(names)
    
    return predictions, image_names

def create_submission(predictions, image_names, output_file='submission.csv'):
    """
    Create submission CSV file
    """
    # Create submission dataframe
    submission_df = pd.DataFrame({
        'id_code': image_names,
        'diagnosis': predictions
    })
    
    # Sort by id_code for consistency
    submission_df = submission_df.sort_values('id_code').reset_index(drop=True)
    
    # Save to CSV
    submission_df.to_csv(output_file, index=False)
    
    print(f"\n{'='*70}")
    print("SUBMISSION CREATED SUCCESSFULLY")
    print(f"{'='*70}")
    print(f"Output file: {output_file}")
    print(f"Total predictions: {len(submission_df)}")
    
    # Show prediction distribution
    pred_counts = submission_df['diagnosis'].value_counts().sort_index()
    print("\nPrediction distribution:")
    for diagnosis, count in pred_counts.items():
        percentage = count / len(submission_df) * 100
        print(f"  Class {diagnosis}: {count:4d} images ({percentage:5.1f}%)")
    
    # Show first few predictions
    print(f"\nFirst 10 predictions:")
    print(submission_df.head(10).to_string(index=False))
    
    return submission_df

def main():
    """
    Main inference function
    """
    # Configuration - Update these paths according to your setup
    config = {
        'model_path': '/kaggle/input/diabetic-retinopathy-rg/best_rg_model.pth',
        'test_csv': '/kaggle/input/aptos2019-blindness-detection/test.csv',
        'test_img_dir': '/kaggle/input/aptos2019-blindness-detection/test_images',
        'normalization_stats_path': '/kaggle/input/diabetic-retinopathy-rg/rg_normalization_stats.json',  # Update if you have this file
        'batch_size': 32,
        'num_classes': 5,
        'dropout_rate': 0.5,
        'use_tta': True,  # Test Time Augmentation
        'output_file': 'submission.csv'
    }
    
    print("="*70)
    print("DIABETIC RETINOPATHY RG MODEL INFERENCE")
    print("="*70)
    
    # Load normalization statistics
    rg_mean, rg_std = load_normalization_stats(config['normalization_stats_path'])
    
    # Create transform
    test_transform = RGTransforms(
        size=(512, 512), 
        mean=rg_mean, 
        std=rg_std
    )
    
    # Create test dataset and loader
    test_dataset = DiabeticRetinopathyRGTestDataset(
        config['test_csv'],
        config['test_img_dir'],
        test_transform
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )
    
    print(f"Test loader: {len(test_loader)} batches")
    
    # Load trained model
    model = load_trained_model(
        config['model_path'],
        config['num_classes'],
        config['dropout_rate']
    )
    
    # Run inference
    predictions, image_names = run_inference(
        model, 
        test_loader, 
        use_tta=config['use_tta']
    )
    
    # Create submission
    submission_df = create_submission(
        predictions, 
        image_names, 
        config['output_file']
    )
    
    print(f"\nðŸŽ‰ Inference completed successfully!")
    print(f"Submission file '{config['output_file']}' is ready for upload.")
    
    return submission_df

if __name__ == "__main__":
    submission_df = main()
