import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import os
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Install and import timm
try:
    import timm
    print("timm imported successfully")
except ImportError:
    print("Installing timm...")
    import subprocess
    import sys
    subprocess.run([sys.executable, '-m', 'pip', 'install', 'timm'])
    import timm
    print("timm installed and imported successfully")

def crop_black_background(image, threshold=10):
    """
    Crop black background from retinal images
    """
    # Convert to grayscale for processing
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image
    
    # Create mask for non-black pixels
    mask = gray > threshold
    
    # Find bounding box of non-black region
    coords = np.argwhere(mask)
    if len(coords) == 0:
        return image  # Return original if no non-black pixels found
    
    y0, x0 = coords.min(axis=0)
    y1, x1 = coords.max(axis=0) + 1
    
    # Crop the image
    cropped = image[y0:y1, x0:x1]
    
    return cropped

class DiabeticRetinopathyRGBYCbCrDataset(Dataset):
    """
    Enhanced Dataset for Diabetic Retinopathy with RGB + YCbCr fusion
    """
    def __init__(self, csv_file, img_dir, is_test=False, image_size=384):
        """
        Args:
            csv_file (string): Path to csv with image names
            img_dir (string): Directory with all images
            is_test (bool): Whether this is test dataset (no labels)
            image_size (int): Target image size (384x384)
        """
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.is_test = is_test
        self.image_size = image_size
        
        print(f"Test dataset loaded: {len(self.data)} images")
        
    def __len__(self):
        return len(self.data)
    
    def preprocess_image(self, image_path):
        """
        Enhanced preprocessing with black background cropping
        """
        # Load image
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Could not load image: {image_path}")
        
        # Convert BGR to RGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Crop black background
        image = crop_black_background(image, threshold=10)
        
        # Resize to target size
        image = cv2.resize(image, (self.image_size, self.image_size))
        
        return image
    
    def rgb_to_ycbcr(self, rgb_image):
        """
        Convert RGB image to YCbCr with proper normalization (MATCHING TRAINING)
        """
        # Convert RGB to YCbCr using cv2
        ycbcr_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2YCrCb)
        
        # Normalize YCbCr channels properly (EXACTLY LIKE TRAINING)
        ycbcr_image = ycbcr_image.astype(np.float32)
        ycbcr_image[:, :, 0] = (ycbcr_image[:, :, 0] - 16) / (235 - 16)  # Y
        ycbcr_image[:, :, 1] = (ycbcr_image[:, :, 1] - 16) / (240 - 16)  # Cb
        ycbcr_image[:, :, 2] = (ycbcr_image[:, :, 2] - 16) / (240 - 16)  # Cr
        
        return ycbcr_image
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        # Get image name
        img_name = self.data.iloc[idx, 0]
        
        # Try different extensions
        img_extensions = ['.jpeg', '.jpg', '.png']
        img_path = None
        
        for ext in img_extensions:
            potential_path = os.path.join(self.img_dir, f"{img_name}{ext}")
            if os.path.exists(potential_path):
                img_path = potential_path
                break
                
        if img_path is None:
            raise FileNotFoundError(f"Image {img_name} not found with any extension")
        
        # Load and preprocess image
        rgb_image = self.preprocess_image(img_path)
        
        # Convert to YCbCr with proper normalization (MATCHING TRAINING)
        ycbcr_image = self.rgb_to_ycbcr(rgb_image)
        
        # Convert to tensors (NO AUGMENTATION FOR INFERENCE)
        rgb_tensor = torch.from_numpy(rgb_image.transpose(2, 0, 1)).float() / 255.0
        ycbcr_tensor = torch.from_numpy(ycbcr_image.transpose(2, 0, 1)).float()
        
        # Normalize RGB with ImageNet stats (MATCHING TRAINING)
        rgb_tensor = transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        )(rgb_tensor)
        
        # YCbCr is already normalized to [0, 1] range (NO ADDITIONAL NORMALIZATION)
        
        return (rgb_tensor, ycbcr_tensor), img_name

class SEResNeXtBackbone(nn.Module):
    """
    SE-ResNeXt26 (26×4d) backbone wrapper for feature extraction
    """
    def __init__(self, model_name='seresnext26d_32x4d', pretrained=False):
        super(SEResNeXtBackbone, self).__init__()
        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0)
        self.feature_dim = self.model.num_features
        
    def forward(self, x):
        return self.model(x)

class EnhancedDualStreamFusionSEResNeXt(nn.Module):
    """
    Enhanced fusion with improved attention mechanism using SE-ResNeXt26 (26×4d) backbones
    """
    def __init__(self, num_classes=5, dropout_rate=0.5, model_name='seresnext26d_32x4d'):
        super(EnhancedDualStreamFusionSEResNeXt, self).__init__()
        
        # RGB stream with SE-ResNeXt26
        self.rgb_backbone = SEResNeXtBackbone(model_name=model_name, pretrained=False)
        rgb_features = self.rgb_backbone.feature_dim
        
        # YCbCr stream with SE-ResNeXt26
        self.ycbcr_backbone = SEResNeXtBackbone(model_name=model_name, pretrained=False)
        ycbcr_features = self.ycbcr_backbone.feature_dim
        
        # Improved attention mechanism for feature fusion
        self.attention = nn.Sequential(
            nn.Linear(rgb_features + ycbcr_features, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate/2),
            nn.Linear(256, 2),
            nn.Softmax(dim=1)
        )
        
        # Final classifier with enhanced architecture
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(rgb_features + ycbcr_features, 1024),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(1024),
            nn.Dropout(dropout_rate/2),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.BatchNorm1d(512),
            nn.Dropout(dropout_rate/2),
            nn.Linear(512, num_classes)
        )
        
    def forward(self, x):
        rgb, ycbcr = x
        
        rgb_features = self.rgb_backbone(rgb)
        ycbcr_features = self.ycbcr_backbone(ycbcr)
        
        # Flatten features (SE-ResNeXt returns 4D tensor)
        rgb_features = rgb_features.view(rgb_features.size(0), -1)
        ycbcr_features = ycbcr_features.view(ycbcr_features.size(0), -1)
        
        # Concatenate features
        combined = torch.cat([rgb_features, ycbcr_features], dim=1)
        
        # Calculate attention weights
        attention_weights = self.attention(combined)
        
        # Apply attention with residual connection (MATCHING TRAINING)
        weighted_rgb = attention_weights[:, 0:1] * rgb_features + rgb_features * 0.1
        weighted_ycbcr = attention_weights[:, 1:2] * ycbcr_features + ycbcr_features * 0.1
        
        # Final fusion
        fused_features = torch.cat([weighted_rgb, weighted_ycbcr], dim=1)
        
        return self.classifier(fused_features)

def load_trained_model(model_path, num_classes=5, dropout_rate=0.5):
    """
    Load the pre-trained RGB+YCbCr fusion model with SE-ResNeXt26
    """
    print(f"Loading model from: {model_path}")
    
    # Initialize model architecture
    model = EnhancedDualStreamFusionSEResNeXt(
        num_classes=num_classes, 
        dropout_rate=dropout_rate,
        model_name='seresnext26d_32x4d'
    )
    
    # Load trained weights
    checkpoint = torch.load(model_path, map_location=device)
    
    # Handle both state_dict and full model save formats
    if 'state_dict' in checkpoint:
        model.load_state_dict(checkpoint['state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model.to(device)
    model.eval()
    
    print("Model loaded successfully!")
    print(f"Total parameters: {sum(p.numel() for p in model.parameters()):,}")
    return model

def generate_predictions(model, test_loader, use_tta=False):
    """
    Generate predictions for test set
    """
    model.eval()
    predictions = []
    image_names = []
    all_probabilities = []
    
    print("Generating predictions...")
    
    with torch.no_grad():
        for data, names in tqdm(test_loader, desc="Processing test images"):
            # data is a tuple of (rgb_tensor, ycbcr_tensor)
            rgb_data, ycbcr_data = data
            rgb_data = rgb_data.to(device)
            ycbcr_data = ycbcr_data.to(device)
            
            if use_tta:
                # Test Time Augmentation for dual-stream model
                outputs = model((rgb_data, ycbcr_data))
                
                # Horizontal flip
                rgb_flip_h = torch.flip(rgb_data, dims=[3])
                ycbcr_flip_h = torch.flip(ycbcr_data, dims=[3])
                outputs += model((rgb_flip_h, ycbcr_flip_h))
                
                # Vertical flip
                rgb_flip_v = torch.flip(rgb_data, dims=[2])
                ycbcr_flip_v = torch.flip(ycbcr_data, dims=[2])
                outputs += model((rgb_flip_v, ycbcr_flip_v))
                
                # Average the predictions
                outputs = outputs / 3.0
            else:
                outputs = model((rgb_data, ycbcr_data))
            
            # Convert logits to probabilities
            probs = torch.softmax(outputs, dim=1)
            
            # Get predicted classes
            preds = probs.argmax(dim=1)
            
            predictions.extend(preds.cpu().numpy())
            image_names.extend(names)
            all_probabilities.extend(probs.cpu().numpy())
    
    return predictions, image_names, np.array(all_probabilities)

def create_submission_file(predictions, image_names, output_file='submission.csv'):
    """
    Create submission file in Kaggle format
    """
    submission_df = pd.DataFrame({
        'id_code': image_names,
        'diagnosis': predictions
    })
    
    # Sort by id_code to ensure consistent ordering
    submission_df = submission_df.sort_values('id_code')
    
    # Save to CSV
    submission_df.to_csv(output_file, index=False)
    
    print(f"Submission file saved: {output_file}")
    print(f"Total predictions: {len(submission_df)}")
    
    # Print prediction distribution
    print("\nPrediction distribution:")
    label_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative']
    for i, label in enumerate(label_names):
        count = (submission_df['diagnosis'] == i).sum()
        percentage = count / len(submission_df) * 100
        print(f"  Class {i} ({label}): {count} images ({percentage:.1f}%)")
    
    return submission_df

def main():
    """
    Main inference pipeline for RGB+YCbCr fusion model with SE-ResNeXt26
    """
    # Configuration
    config = {
        'model_path': '/kaggle/input/rgb-ycbcr-se-resnext26-26-4d-final-2training/best_dual_stream_seresnext_model.pth',  # Update with your model path
        'test_csv': '/kaggle/input/aptos2019-blindness-detection/test.csv',
        'test_img_dir': '/kaggle/input/aptos2019-blindness-detection/test_images',
        'batch_size': 16,
        'num_classes': 5,
        'dropout_rate': 0.5,
        'use_tta': True,  # Use Test Time Augmentation for better results
        'output_file': 'submission.csv',
        'image_size': 384  # Match training image size
    }
    
    print("="*70)
    print("ENHANCED DUAL-STREAM RGB+YCbCr FUSION MODEL - INFERENCE")
    print("Backbone: SE-ResNeXt26 (26×4d)")
    print("Image Size: 384x384")
    print("="*70)
    print("Configuration:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    print("="*70)
    
    # Check if test files exist
    if not os.path.exists(config['test_csv']):
        print(f"Error: Test CSV file not found at {config['test_csv']}")
        return
    
    if not os.path.exists(config['test_img_dir']):
        print(f"Error: Test images directory not found at {config['test_img_dir']}")
        return
    
    if not os.path.exists(config['model_path']):
        print(f"Error: Model file not found at {config['model_path']}")
        print("Please make sure the model file exists or update the model_path in the config.")
        return
    
    # Load trained model
    model = load_trained_model(
        config['model_path'], 
        config['num_classes'], 
        config['dropout_rate']
    )
    
    # Load test dataset
    print("\nLoading test data...")
    test_dataset = DiabeticRetinopathyRGBYCbCrDataset(
        csv_file=config['test_csv'],
        img_dir=config['test_img_dir'],
        is_test=True,
        image_size=config['image_size']
    )
    
    # Create test data loader
    test_loader = DataLoader(
        test_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=2,
        pin_memory=True
    )
    
    # Generate predictions
    print(f"\nGenerating predictions with TTA: {config['use_tta']}")
    predictions, image_names, probabilities = generate_predictions(
        model, 
        test_loader, 
        use_tta=config['use_tta']
    )
    
    # Create submission file
    print("\nCreating submission file...")
    submission_df = create_submission_file(
        predictions, 
        image_names, 
        config['output_file']
    )
    
    print("\n" + "="*70)
    print("INFERENCE COMPLETED SUCCESSFULLY!")
    print("="*70)
    print(f"Submission file: {config['output_file']}")
    print(f"Total test images processed: {len(predictions)}")
    print("="*70)
    
    return submission_df

if __name__ == "__main__":
    # Set random seeds for reproducibility
    torch.manual_seed(42)
    np.random.seed(42)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    # Run inference
    submission_df = main()
