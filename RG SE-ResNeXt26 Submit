import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import os
from tqdm import tqdm
import warnings
import json
import random
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

def crop_black_background(image, threshold=10):
    """
    Crop black background from retinal images - SAME AS TRAINING
    """
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image
    
    mask = gray > threshold
    coords = np.argwhere(mask)
    if len(coords) == 0:
        return image
    
    y0, x0 = coords.min(axis=0)
    y1, x1 = coords.max(axis=0) + 1
    cropped = image[y0:y1, x0:x1]
    return cropped

class DiabeticRetinopathyRGDataset(Dataset):
    """
    RG Dataset for inference - MATCHING TRAINING PREPROCESSING
    """
    def __init__(self, csv_file, img_dir, rg_mean, rg_std, image_size=384):
        """
        Args:
            csv_file (string): Path to csv with image names
            img_dir (string): Directory with all images
            rg_mean (list): RG channel means for normalization
            rg_std (list): RG channel stds for normalization
            image_size (int): Target image size (384x384)
        """
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.rg_mean = rg_mean
        self.rg_std = rg_std
        self.image_size = image_size
        
        print(f"RG Test dataset loaded: {len(self.data)} images")
        print(f"RG Normalization - Mean: {rg_mean}, Std: {rg_std}")
        
    def __len__(self):
        return len(self.data)
    
    def preprocess_image(self, image_path):
        """SAME preprocessing as training"""
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Could not load image: {image_path}")
        
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = crop_black_background(image, threshold=10)  # SAME CROPPING
        image = cv2.resize(image, (self.image_size, self.image_size))  # SAME SIZE
        
        # Extract RG channels
        image_rg = np.zeros((image.shape[0], image.shape[1], 2), dtype=np.uint8)
        image_rg[:, :, 0] = image[:, :, 0]  # Red channel
        image_rg[:, :, 1] = image[:, :, 1]  # Green channel
        
        return image_rg
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        # Get image name
        if 'id_code' in self.data.columns:
            img_name = self.data.iloc[idx]['id_code']
        else:
            img_name = self.data.iloc[idx, 0]
        
        # Try different extensions
        img_extensions = ['.png', '.jpg', '.jpeg']
        img_path = None
        
        for ext in img_extensions:
            potential_path = os.path.join(self.img_dir, f"{img_name}{ext}")
            if os.path.exists(potential_path):
                img_path = potential_path
                break
                
        if img_path is None:
            raise FileNotFoundError(f"Image {img_name} not found with any extension")
    
        try:
            # Use same preprocessing as training
            image_rg = self.preprocess_image(img_path)
            
            # Convert to tensor
            image_tensor = torch.from_numpy(image_rg.transpose(2, 0, 1)).float() / 255.0
            
            # Apply RG-specific normalization
            for i in range(2):
                image_tensor[i] = (image_tensor[i] - self.rg_mean[i]) / self.rg_std[i]
                
        except Exception as e:
            print(f"Error processing image {img_name}: {e}")
            image_tensor = torch.zeros((2, self.image_size, self.image_size), dtype=torch.float32)
        
        return image_tensor, img_name

class RGResNeXtModel(nn.Module):
    """
    RG Channel SE-ResNeXt model - SAME AS TRAINING
    """
    def __init__(self, num_classes=5, dropout_rate=0.5, model_name='seresnext26d_32x4d'):
        super(RGResNeXtModel, self).__init__()
        
        # Import timm locally
        import timm
        
        # Load SE-ResNeXt with 2 input channels
        self.backbone = timm.create_model(
            model_name, 
            pretrained=False,  # We'll load weights from file
            num_classes=0,  # Remove classification head
            in_chans=2      # 2 input channels for RG
        )
        feature_dim = self.backbone.num_features
        
        # Same classifier as training
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(feature_dim, 1024),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate/2),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate/2),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        features = self.backbone(x)
        output = self.classifier(features)
        return output

def load_rg_normalization_stats(stats_path='rg_seresnext_normalization_stats.json'):
    """
    Load RG normalization statistics from training
    """
    if not os.path.exists(stats_path):
        print(f"Warning: Normalization stats file not found at {stats_path}")
        print("Using default RG normalization")
        return [0.5, 0.5], [0.5, 0.5], 384
    
    with open(stats_path, 'r') as f:
        stats = json.load(f)
    
    rg_mean = stats['rg_mean']
    rg_std = stats['rg_std']
    image_size = stats.get('image_size', 384)
    
    print(f"Loaded RG normalization: mean={rg_mean}, std={rg_std}, size={image_size}")
    return rg_mean, rg_std, image_size

def load_trained_rg_model(model_path, num_classes=5, dropout_rate=0.5):
    """
    Load the trained RG SE-ResNeXt model
    """
    print(f"Loading RG SE-ResNeXt model from: {model_path}")
    
    # Initialize model
    model = RGResNeXtModel(
        num_classes=num_classes,
        dropout_rate=dropout_rate,
        model_name='seresnext26d_32x4d'
    )
    
    # Load trained weights with safe handling
    try:
        if torch.cuda.is_available():
            checkpoint = torch.load(model_path, map_location=device, weights_only=True)
        else:
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
        print("Model loaded safely with weights_only=True")
    except:
        print("Safe loading failed, trying with weights_only=False")
        if torch.cuda.is_available():
            checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        else:
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        print("Model loaded with weights_only=False")
    
    # Handle different checkpoint formats
    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"Loaded model from epoch {checkpoint.get('epoch', 'unknown')}")
        print(f"Best QWK during training: {checkpoint.get('best_kappa', 'unknown')}")
    else:
        model.load_state_dict(checkpoint)
    
    model.to(device)
    model.eval()
    
    print("RG SE-ResNeXt model loaded successfully!")
    return model

def perform_rg_inference(model, test_loader, use_tta=True):
    """
    Perform inference on test dataset with optional Test Time Augmentation
    """
    model.eval()
    predictions = []
    image_names = []
    all_probabilities = []
    
    print("Performing RG channel inference...")
    
    with torch.no_grad():
        for data, img_names in tqdm(test_loader, desc="RG Inference"):
            data = data.to(device)
            
            if use_tta:
                # Test Time Augmentation for RG channels
                tta_predictions = []
                
                # Original
                output = model(data)
                tta_predictions.append(torch.softmax(output, dim=1))
                
                # Horizontal flip
                data_flipped = torch.flip(data, dims=[3])
                output_flipped = model(data_flipped)
                tta_predictions.append(torch.softmax(output_flipped, dim=1))
                
                # Vertical flip
                data_vflipped = torch.flip(data, dims=[2])
                output_vflipped = model(data_vflipped)
                tta_predictions.append(torch.softmax(output_vflipped, dim=1))
                
                # Average predictions
                avg_prediction = torch.mean(torch.stack(tta_predictions), dim=0)
                pred_classes = avg_prediction.argmax(dim=1)
                probabilities = avg_prediction.cpu().numpy()
                
            else:
                # No TTA - single prediction
                output = model(data)
                probabilities = torch.softmax(output, dim=1).cpu().numpy()
                pred_classes = output.argmax(dim=1)
            
            predictions.extend(pred_classes.cpu().numpy())
            image_names.extend(img_names)
            all_probabilities.extend(probabilities)
    
    return predictions, image_names, np.array(all_probabilities)

def create_submission(predictions, image_names, output_file='rg_seresnext_submission.csv'):
    """
    Create submission CSV file
    """
    print(f"Creating RG submission file: {output_file}")
    
    # Create submission dataframe
    submission_df = pd.DataFrame({
        'id_code': image_names,
        'diagnosis': predictions
    })
    
    # Sort by id_code for consistent ordering
    submission_df = submission_df.sort_values('id_code')
    
    # Save submission
    submission_df.to_csv(output_file, index=False)
    
    print(f"RG submission file created with {len(submission_df)} predictions")
    
    # Print prediction distribution
    print("\nRG Model Prediction distribution:")
    label_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative']
    for i, label in enumerate(label_names):
        count = (submission_df['diagnosis'] == i).sum()
        percentage = count / len(submission_df) * 100
        print(f"  Class {i} ({label}): {count} images ({percentage:.1f}%)")
    
    return submission_df

def main():
    """
    Main inference pipeline for RG SE-ResNeXt model
    """
    # Configuration - UPDATE THESE PATHS
    config = {
        'model_path': '/kaggle/input/rg-se-resnext26-training/best_rg_seresnext_model.pth',  # Update with your model path
        'normalization_stats_path': '/kaggle/input/rg-se-resnext26-training/rg_seresnext_normalization_stats.json',  # Update path
        'test_csv': '/kaggle/input/aptos2019-blindness-detection/test.csv',
        'test_img_dir': '/kaggle/input/aptos2019-blindness-detection/test_images',
        'batch_size': 16,
        'num_classes': 5,
        'dropout_rate': 0.5,
        'use_tta': True,  # Use Test Time Augmentation
        'output_file': 'submission.csv'
    }
    
    print("="*70)
    print("RG SE-RESNEXT DIABETIC RETINOPATHY INFERENCE")
    print("="*70)
    print(f"Model: SE-ResNeXt-26x4d (RG channels only)")
    print(f"Model path: {config['model_path']}")
    print(f"Test CSV: {config['test_csv']}")
    print(f"Test images: {config['test_img_dir']}")
    print(f"Batch size: {config['batch_size']}")
    print(f"TTA enabled: {config['use_tta']}")
    print("="*70)
    
    # Check if model file exists
    if not os.path.exists(config['model_path']):
        print(f"Error: Model file not found at {config['model_path']}")
        print("Please update the model_path in the config dictionary.")
        return
    
    # Check if test files exist
    if not os.path.exists(config['test_csv']):
        print(f"Error: Test CSV file not found at {config['test_csv']}")
        return
    
    if not os.path.exists(config['test_img_dir']):
        print(f"Error: Test images directory not found at {config['test_img_dir']}")
        return
    
    # Load RG normalization statistics
    if config['normalization_stats_path'] and os.path.exists(config['normalization_stats_path']):
        rg_mean, rg_std, image_size = load_rg_normalization_stats(config['normalization_stats_path'])
    else:
        print("Warning: No normalization stats file found, using defaults")
        rg_mean, rg_std, image_size = [0.5, 0.5], [0.5, 0.5], 384
    
    # Load trained RG model
    model = load_trained_rg_model(
        config['model_path'],
        num_classes=config['num_classes'],
        dropout_rate=config['dropout_rate']
    )
    
    # Create test dataset with RG preprocessing
    print("\nLoading RG test dataset...")
    test_dataset = DiabeticRetinopathyRGDataset(
        csv_file=config['test_csv'],
        img_dir=config['test_img_dir'],
        rg_mean=rg_mean,
        rg_std=rg_std,
        image_size=image_size
    )
    
    # Create test data loader
    test_loader = DataLoader(
        test_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )
    
    # Perform inference
    print(f"\nStarting RG SE-ResNeXt inference with TTA: {config['use_tta']}")
    predictions, image_names, probabilities = perform_rg_inference(
        model, 
        test_loader, 
        use_tta=config['use_tta']
    )
    
    # Create submission file
    submission_df = create_submission(
        predictions, 
        image_names, 
        config['output_file']
    )
    
    # Save prediction probabilities for analysis
    prob_df = pd.DataFrame(probabilities, columns=[f'class_{i}' for i in range(5)])
    prob_df['id_code'] = image_names
    prob_df['prediction'] = predictions
    prob_df.to_csv('rg_seresnext_prediction_probabilities.csv', index=False)
    print("Prediction probabilities saved to 'rg_seresnext_prediction_probabilities.csv'")
    
    print(f"\n" + "="*70)
    print("RG SE-RESNEXT INFERENCE COMPLETED SUCCESSFULLY!")
    print("="*70)
    print(f"Submission file: {config['output_file']}")
    print(f"Total test images processed: {len(predictions)}")
    print(f"Model used: RG (Red-Green) Channel SE-ResNeXt-26x4d")
    print(f"Image resolution: {image_size}x{image_size}")
    print(f"TTA used: {config['use_tta']}")
    print(f"RG Normalization: mean={rg_mean}, std={rg_std}")
    print("="*70)
    
    return submission_df

if __name__ == "__main__":
    # Set random seeds for reproducibility
    torch.manual_seed(42)
    np.random.seed(42)
    random.seed(42)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    # Run inference
    submission_df = main()
