import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import os
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class DiabeticRetinopathyNormalizedDataset(Dataset):
    """
    Custom Dataset for Diabetic Retinopathy with normalized color channels
    Creates features like R/(R+G), G/(R+G), etc. instead of standard RGB
    """
    def __init__(self, csv_file, img_dir, transform=None, is_test=False, normalization_type='rg_ratio'):
        """
        Args:
            csv_file (string): Path to csv with image names and labels
            img_dir (string): Directory with all images
            transform (callable, optional): Transform to be applied on images
            is_test (bool): Whether this is test dataset (no labels)
            normalization_type (str): Type of normalization to apply
                - 'rg_ratio': R/(R+G), G/(R+G)
                - 'rgb_ratio': R/(R+G+B), G/(R+G+B), B/(R+G+B)
                - 'combined': RGB + normalized ratios (6 channels)
        """
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test
        self.normalization_type = normalization_type
        
        # Print dataset statistics
        if not is_test:
            print(f"Dataset loaded: {len(self.data)} images")
            print(f"Using normalization type: {normalization_type}")
            label_counts = self.data.iloc[:, 1].value_counts().sort_index()
            print("Label distribution:")
            for label, count in label_counts.items():
                print(f"  Class {label}: {count} images ({count/len(self.data)*100:.1f}%)")
        else:
            print(f"Test dataset loaded: {len(self.data)} images")
            print(f"Using normalization type: {normalization_type}")
        
    def normalize_color_channels(self, image):
        """
        Apply color channel normalization based on the specified type
        
        Args:
            image: numpy array of shape (H, W, 3) with RGB values
            
        Returns:
            normalized_image: numpy array with normalized channels
        """
        # Convert to float to avoid division issues
        image = image.astype(np.float32)
        
        # Add small epsilon to avoid division by zero
        eps = 1e-8
        
        R = image[:, :, 0]
        G = image[:, :, 1]
        B = image[:, :, 2]
        
        if self.normalization_type == 'rg_ratio':
            # Create R/(R+G) and G/(R+G) channels
            RG_sum = R + G + eps
            R_norm = R / RG_sum
            G_norm = G / RG_sum
            # Stack to create 2-channel image
            normalized_image = np.stack([R_norm, G_norm], axis=2)
            
        elif self.normalization_type == 'rgb_ratio':
            # Create R/(R+G+B), G/(R+G+B), B/(R+G+B) channels
            RGB_sum = R + G + B + eps
            R_norm = R / RGB_sum
            G_norm = G / RGB_sum
            B_norm = B / RGB_sum
            # Stack to create 3-channel image
            normalized_image = np.stack([R_norm, G_norm, B_norm], axis=2)
            
        elif self.normalization_type == 'combined':
            # Keep original RGB and add normalized ratios (6 channels total)
            RGB_sum = R + G + B + eps
            R_norm = R / RGB_sum
            G_norm = G / RGB_sum
            B_norm = B / RGB_sum
            
            # Normalize RGB to 0-1 range for consistency
            R_orig = R / 255.0
            G_orig = G / 255.0  
            B_orig = B / 255.0
            
            # Stack original + normalized channels
            normalized_image = np.stack([R_orig, G_orig, B_orig, R_norm, G_norm, B_norm], axis=2)
            
        else:
            raise ValueError(f"Unknown normalization type: {self.normalization_type}")
        
        # Ensure values are in valid range [0, 1]
        normalized_image = np.clip(normalized_image, 0, 1)
        
        return normalized_image
        
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        # Get image name
        img_name = self.data.iloc[idx, 0]
        
        # Try different extensions
        img_extensions = ['.jpeg', '.jpg', '.png']
        img_path = None
        
        for ext in img_extensions:
            potential_path = os.path.join(self.img_dir, f"{img_name}{ext}")
            if os.path.exists(potential_path):
                img_path = potential_path
                break
                
        if img_path is None:
            raise FileNotFoundError(f"Image {img_name} not found with any extension")
        
        # Load image in standard RGB format
        image = cv2.imread(img_path)
        if image is None:
            raise ValueError(f"Could not load image: {img_path}")
        
        # Convert BGR to RGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Apply color normalization
        image = self.normalize_color_channels(image)
        
        # Convert to PIL Image format for transforms (convert back to 0-255 range)
        image_pil = Image.fromarray((image * 255).astype(np.uint8))
        
        if self.transform:
            image = self.transform(image_pil)
            
        if not self.is_test:
            label = int(self.data.iloc[idx, 1])
            return image, label
        else:
            return image, img_name

class DRNormalizedClassifier(nn.Module):
    """
    Diabetic Retinopathy Classifier using normalized color channels
    Adapts input layer to handle different numbers of channels
    """
    def __init__(self, num_classes=5, pretrained=False, dropout_rate=0.5, input_channels=2):
        super(DRNormalizedClassifier, self).__init__()
        
        # Use ResNet50 as backbone
        self.backbone = models.resnet50(pretrained=pretrained)
        
        # Modify first convolutional layer to accept different input channels
        if input_channels != 3:
            # Get the original first conv layer
            original_conv = self.backbone.conv1
            
            # Create new conv layer with desired input channels
            self.backbone.conv1 = nn.Conv2d(
                input_channels, 
                original_conv.out_channels,
                kernel_size=original_conv.kernel_size,
                stride=original_conv.stride,
                padding=original_conv.padding,
                bias=original_conv.bias
            )
            
            # Initialize weights
            if pretrained and input_channels < 3:
                # For fewer channels, average the original weights
                with torch.no_grad():
                    # Average across input channels and repeat
                    avg_weight = original_conv.weight.mean(dim=1, keepdim=True)
                    self.backbone.conv1.weight = nn.Parameter(
                        avg_weight.repeat(1, input_channels, 1, 1)
                    )
            elif pretrained and input_channels > 3:
                # For more channels, duplicate and pad
                with torch.no_grad():
                    old_weight = original_conv.weight
                    new_weight = torch.zeros(original_conv.out_channels, input_channels, 7, 7)
                    # Copy original RGB weights
                    new_weight[:, :3, :, :] = old_weight
                    # Initialize additional channels with average of RGB
                    avg_weight = old_weight.mean(dim=1, keepdim=True)
                    for i in range(3, input_channels):
                        new_weight[:, i:i+1, :, :] = avg_weight
                    self.backbone.conv1.weight = nn.Parameter(new_weight)
            else:
                # Random initialization for non-pretrained
                nn.init.kaiming_normal_(self.backbone.conv1.weight, mode='fan_out', nonlinearity='relu')
        
        # Store original fc layer input features
        num_features = self.backbone.fc.in_features
        
        # Replace final layer with custom classifier
        self.backbone.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(num_features, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate/2),
            nn.Linear(512, num_classes)
        )
        
        # Initialize weights for new layers
        for m in self.backbone.fc.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                nn.init.constant_(m.bias, 0)
        
    def forward(self, x):
        return self.backbone(x)

def get_normalized_transforms(num_channels=2):
    """
    Define transforms for normalized color channels
    Note: We don't use ImageNet normalization since our channels are different
    """
    if num_channels == 2:
        # For R/(R+G), G/(R+G) channels
        mean = [0.5, 0.5]
        std = [0.25, 0.25]
    elif num_channels == 3:
        # For R/(R+G+B), G/(R+G+B), B/(R+G+B) channels  
        mean = [0.33, 0.33, 0.33]
        std = [0.2, 0.2, 0.2]
    elif num_channels == 6:
        # For combined RGB + normalized channels
        mean = [0.485, 0.456, 0.406, 0.33, 0.33, 0.33]
        std = [0.229, 0.224, 0.225, 0.2, 0.2, 0.2]
    else:
        # Default normalization
        mean = [0.5] * num_channels
        std = [0.25] * num_channels
    
    val_transforms = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean, std=std)
    ])
    
    return val_transforms

def generate_submission(model_path, test_csv, test_img_dir, output_csv='submission.csv'):
    """
    Generate submission file for the test dataset
    """
    # Configuration (should match your training configuration)
    config = {
        'test_csv': test_csv,
        'test_img_dir': test_img_dir,
        'batch_size': 16,
        'num_classes': 5,
        'dropout_rate': 0.5,
        'normalization_type': 'rg_ratio'  # Should match your training config
    }
    
    # Determine number of input channels based on normalization type
    channel_mapping = {
        'rg_ratio': 2,      # R/(R+G), G/(R+G)
        'rgb_ratio': 3,     # R/(R+G+B), G/(R+G+B), B/(R+G+B)  
        'combined': 6       # RGB + normalized ratios
    }
    
    input_channels = channel_mapping[config['normalization_type']]
    
    print("="*70)
    print("GENERATING SUBMISSION FILE")
    print("="*70)
    print(f"Model path: {model_path}")
    print(f"Test CSV: {config['test_csv']}")
    print(f"Test images: {config['test_img_dir']}")
    print(f"Normalization type: {config['normalization_type']}")
    print(f"Input channels: {input_channels}")
    print("="*70)
    
    # Get transforms
    test_transforms = get_normalized_transforms(input_channels)
    
    # Load test dataset
    test_dataset = DiabeticRetinopathyNormalizedDataset(
        csv_file=config['test_csv'],
        img_dir=config['test_img_dir'],
        transform=test_transforms,
        is_test=True,
        normalization_type=config['normalization_type']
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=4,
        pin_memory=True
    )
    
    # Initialize model
    model = DRNormalizedClassifier(
        num_classes=config['num_classes'],
        dropout_rate=config['dropout_rate'],
        input_channels=input_channels
    )
    
    # Load trained weights
    print(f"\nLoading model weights from: {model_path}")
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    
    print("Model loaded successfully!")
    
    # Generate predictions
    predictions = []
    image_names = []
    
    print(f"\nGenerating predictions for {len(test_dataset)} test images...")
    
    with torch.no_grad():
        for batch_idx, (data, img_names) in enumerate(tqdm(test_loader, desc="Predicting")):
            data = data.to(device)
            outputs = model(data)
            
            # Get predicted classes
            _, predicted = torch.max(outputs.data, 1)
            
            # Store predictions and image names
            predictions.extend(predicted.cpu().numpy())
            image_names.extend(img_names)
    
    # Create submission DataFrame
    submission_df = pd.DataFrame({
        'id_code': image_names,
        'diagnosis': predictions
    })
    
    # Save submission file
    submission_df.to_csv(output_csv, index=False)
    
    print(f"\nSubmission file saved as: {output_csv}")
    print(f"Number of predictions: {len(submission_df)}")
    
    # Print prediction distribution
    print("\nPrediction distribution:")
    pred_counts = submission_df['diagnosis'].value_counts().sort_index()
    total_preds = len(submission_df)
    
    for diagnosis, count in pred_counts.items():
        percentage = (count / total_preds) * 100
        print(f"  Class {diagnosis}: {count} predictions ({percentage:.1f}%)")
    
    print("\nSubmission file ready!")
    return submission_df

# Main execution
if __name__ == "__main__":
    # Update these paths according to your setup
    MODEL_PATH = '/kaggle/input/color-channels-dr-classification-r-r-g-g-r-g/best_normalized_model.pth'
    TEST_CSV = '/kaggle/input/aptos2019-blindness-detection/test.csv'
    TEST_IMG_DIR = '/kaggle/input/aptos2019-blindness-detection/test_images'
    OUTPUT_CSV = 'submission.csv'
    
    # Generate submission
    submission_df = generate_submission(
        model_path=MODEL_PATH,
        test_csv=TEST_CSV,
        test_img_dir=TEST_IMG_DIR,
        output_csv=OUTPUT_CSV
    )
    
    # Display first few rows
    print("\nFirst 10 rows of submission:")
    print(submission_df.head(10))
    
    print(f"\nSubmission file '{OUTPUT_CSV}' is ready for upload!")
