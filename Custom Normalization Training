import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision import models
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import os
from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
import json
from datetime import datetime
warnings.filterwarnings('ignore')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class DiabeticRetinopathyNormalizedDataset(Dataset):
    """
    Custom Dataset for Diabetic Retinopathy with normalized color channels
    Creates features like R/(R+G), G/(R+G), etc. instead of standard RGB
    """
    def __init__(self, csv_file, img_dir, transform=None, is_test=False, normalization_type='rg_ratio'):
        """
        Args:
            csv_file (string): Path to csv with image names and labels
            img_dir (string): Directory with all images
            transform (callable, optional): Transform to be applied on images
            is_test (bool): Whether this is test dataset (no labels)
            normalization_type (str): Type of normalization to apply
                - 'rg_ratio': R/(R+G), G/(R+G)
                - 'rgb_ratio': R/(R+G+B), G/(R+G+B), B/(R+G+B)
                - 'combined': RGB + normalized ratios (6 channels)
        """
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        self.is_test = is_test
        self.normalization_type = normalization_type
        
        # Print dataset statistics
        if not is_test:
            print(f"Dataset loaded: {len(self.data)} images")
            print(f"Using normalization type: {normalization_type}")
            label_counts = self.data.iloc[:, 1].value_counts().sort_index()
            print("Label distribution:")
            for label, count in label_counts.items():
                print(f"  Class {label}: {count} images ({count/len(self.data)*100:.1f}%)")
        
    def normalize_color_channels(self, image):
        """
        Apply color channel normalization based on the specified type
        
        Args:
            image: numpy array of shape (H, W, 3) with RGB values
            
        Returns:
            normalized_image: numpy array with normalized channels
        """
        # Convert to float to avoid division issues
        image = image.astype(np.float32)
        
        # Add small epsilon to avoid division by zero
        eps = 1e-8
        
        R = image[:, :, 0]
        G = image[:, :, 1]
        B = image[:, :, 2]
        
        if self.normalization_type == 'rg_ratio':
            # Create R/(R+G) and G/(R+G) channels
            RG_sum = R + G + eps
            R_norm = R / RG_sum
            G_norm = G / RG_sum
            # Stack to create 2-channel image
            normalized_image = np.stack([R_norm, G_norm], axis=2)
            
        elif self.normalization_type == 'rgb_ratio':
            # Create R/(R+G+B), G/(R+G+B), B/(R+G+B) channels
            RGB_sum = R + G + B + eps
            R_norm = R / RGB_sum
            G_norm = G / RGB_sum
            B_norm = B / RGB_sum
            # Stack to create 3-channel image
            normalized_image = np.stack([R_norm, G_norm, B_norm], axis=2)
            
        elif self.normalization_type == 'combined':
            # Keep original RGB and add normalized ratios (6 channels total)
            RGB_sum = R + G + B + eps
            R_norm = R / RGB_sum
            G_norm = G / RGB_sum
            B_norm = B / RGB_sum
            
            # Normalize RGB to 0-1 range for consistency
            R_orig = R / 255.0
            G_orig = G / 255.0  
            B_orig = B / 255.0
            
            # Stack original + normalized channels
            normalized_image = np.stack([R_orig, G_orig, B_orig, R_norm, G_norm, B_norm], axis=2)
            
        else:
            raise ValueError(f"Unknown normalization type: {self.normalization_type}")
        
        # Ensure values are in valid range [0, 1]
        normalized_image = np.clip(normalized_image, 0, 1)
        
        return normalized_image
        
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
            
        # Get image name
        img_name = self.data.iloc[idx, 0]
        
        # Try different extensions
        img_extensions = ['.jpeg', '.jpg', '.png']
        img_path = None
        
        for ext in img_extensions:
            potential_path = os.path.join(self.img_dir, f"{img_name}{ext}")
            if os.path.exists(potential_path):
                img_path = potential_path
                break
                
        if img_path is None:
            raise FileNotFoundError(f"Image {img_name} not found with any extension")
        
        # Load image in standard RGB format
        image = cv2.imread(img_path)
        if image is None:
            raise ValueError(f"Could not load image: {img_path}")
        
        # Convert BGR to RGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Apply color normalization
        image = self.normalize_color_channels(image)
        
        # Convert to PIL Image format for transforms (convert back to 0-255 range)
        image_pil = Image.fromarray((image * 255).astype(np.uint8))
        
        if self.transform:
            image = self.transform(image_pil)
            
        if not self.is_test:
            label = int(self.data.iloc[idx, 1])
            return image, label
        else:
            return image, img_name

class DRNormalizedClassifier(nn.Module):
    """
    Diabetic Retinopathy Classifier using normalized color channels
    Adapts input layer to handle different numbers of channels
    """
    def __init__(self, num_classes=5, pretrained=True, dropout_rate=0.5, input_channels=2):
        super(DRNormalizedClassifier, self).__init__()
        
        # Use ResNet50 as backbone
        self.backbone = models.resnet50(pretrained=pretrained)
        
        # Modify first convolutional layer to accept different input channels
        if input_channels != 3:
            # Get the original first conv layer
            original_conv = self.backbone.conv1
            
            # Create new conv layer with desired input channels
            self.backbone.conv1 = nn.Conv2d(
                input_channels, 
                original_conv.out_channels,
                kernel_size=original_conv.kernel_size,
                stride=original_conv.stride,
                padding=original_conv.padding,
                bias=original_conv.bias
            )
            
            # Initialize weights
            if pretrained and input_channels < 3:
                # For fewer channels, average the original weights
                with torch.no_grad():
                    # Average across input channels and repeat
                    avg_weight = original_conv.weight.mean(dim=1, keepdim=True)
                    self.backbone.conv1.weight = nn.Parameter(
                        avg_weight.repeat(1, input_channels, 1, 1)
                    )
            elif pretrained and input_channels > 3:
                # For more channels, duplicate and pad
                with torch.no_grad():
                    old_weight = original_conv.weight
                    new_weight = torch.zeros(original_conv.out_channels, input_channels, 7, 7)
                    # Copy original RGB weights
                    new_weight[:, :3, :, :] = old_weight
                    # Initialize additional channels with average of RGB
                    avg_weight = old_weight.mean(dim=1, keepdim=True)
                    for i in range(3, input_channels):
                        new_weight[:, i:i+1, :, :] = avg_weight
                    self.backbone.conv1.weight = nn.Parameter(new_weight)
            else:
                # Random initialization for non-pretrained
                nn.init.kaiming_normal_(self.backbone.conv1.weight, mode='fan_out', nonlinearity='relu')
        
        # Store original fc layer input features
        num_features = self.backbone.fc.in_features
        
        # Replace final layer with custom classifier
        self.backbone.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(num_features, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate/2),
            nn.Linear(512, num_classes)
        )
        
        # Initialize weights for new layers
        for m in self.backbone.fc.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                nn.init.constant_(m.bias, 0)
        
    def forward(self, x):
        return self.backbone(x)

def get_normalized_transforms(num_channels=2):
    """
    Define transforms for normalized color channels
    Note: We don't use ImageNet normalization since our channels are different
    """
    if num_channels == 2:
        # For R/(R+G), G/(R+G) channels
        mean = [0.5, 0.5]
        std = [0.25, 0.25]
    elif num_channels == 3:
        # For R/(R+G+B), G/(R+G+B), B/(R+G+B) channels  
        mean = [0.33, 0.33, 0.33]
        std = [0.2, 0.2, 0.2]
    elif num_channels == 6:
        # For combined RGB + normalized channels
        mean = [0.485, 0.456, 0.406, 0.33, 0.33, 0.33]
        std = [0.229, 0.224, 0.225, 0.2, 0.2, 0.2]
    else:
        # Default normalization
        mean = [0.5] * num_channels
        std = [0.25] * num_channels
    
    train_transforms = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomVerticalFlip(p=0.5),
        transforms.RandomRotation(degrees=15),
        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),
        transforms.RandomResizedCrop(512, scale=(0.8, 1.0)),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean, std=std)
    ])
    
    val_transforms = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean, std=std)
    ])
    
    return train_transforms, val_transforms

def quadratic_weighted_kappa(y_true, y_pred):
    """Calculate Quadratic Weighted Kappa (QWK) score"""
    return cohen_kappa_score(y_true, y_pred, weights='quadratic')

def train_normalized_model(model, train_loader, val_loader, num_epochs=60, learning_rate=1e-4):
    """Train the normalized color channel model"""
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer, T_0=10, T_mult=2, eta_min=1e-6
    )
    
    history = {
        'train_losses': [],
        'val_losses': [],
        'val_kappas': [],
        'val_accuracies': [],
        'learning_rates': []
    }
    
    best_kappa = 0.0
    best_model_state = None
    patience_counter = 0
    patience = 15
    
    print("Starting Normalized Color Model Training...")
    print(f"Training on {len(train_loader.dataset)} samples")
    print(f"Validating on {len(val_loader.dataset)} samples")
    
    for epoch in range(num_epochs):
        # Training phase
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')
        
        for batch_idx, (data, target) in enumerate(train_pbar):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            
            train_loss += loss.item()
            pred = output.argmax(dim=1, keepdim=True)
            train_correct += pred.eq(target.view_as(pred)).sum().item()
            train_total += target.size(0)
            
            current_acc = 100. * train_correct / train_total
            train_pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{current_acc:.2f}%'
            })
        
        avg_train_loss = train_loss / len(train_loader)
        train_accuracy = 100. * train_correct / train_total
        
        # Validation phase
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')
            for data, target in val_pbar:
                data, target = data.to(device), target.to(device)
                output = model(data)
                loss = criterion(output, target)
                val_loss += loss.item()
                
                pred = output.argmax(dim=1, keepdim=True)
                val_correct += pred.eq(target.view_as(pred)).sum().item()
                val_total += target.size(0)
                
                all_preds.extend(pred.cpu().numpy().flatten())
                all_targets.extend(target.cpu().numpy())
                
                current_acc = 100. * val_correct / val_total
                val_pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{current_acc:.2f}%'
                })
        
        avg_val_loss = val_loss / len(val_loader)
        val_accuracy = 100. * val_correct / val_total
        val_kappa = quadratic_weighted_kappa(all_targets, all_preds)
        
        scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']
        
        # Store history
        history['train_losses'].append(avg_train_loss)
        history['val_losses'].append(avg_val_loss)
        history['val_kappas'].append(val_kappa)
        history['val_accuracies'].append(val_accuracy)
        history['learning_rates'].append(current_lr)
        
        # Print epoch results
        print(f'\nEpoch {epoch+1}/{num_epochs}:')
        print(f'  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.2f}%')
        print(f'  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%')
        print(f'  Val QWK: {val_kappa:.4f}')
        print(f'  Learning Rate: {current_lr:.8f}')
        
        # Save best model and early stopping
        if val_kappa > best_kappa:
            best_kappa = val_kappa
            best_model_state = model.state_dict().copy()
            torch.save(best_model_state, 'best_normalized_model.pth')
            patience_counter = 0
            print(f'  ✅ New best model saved! QWK: {best_kappa:.4f}')
        else:
            patience_counter += 1
            
        if patience_counter >= patience:
            print(f'\nEarly stopping triggered after {patience} epochs without improvement.')
            break
            
        print('-' * 70)
    
    # Load best model
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
    
    history['best_kappa'] = best_kappa
    history['total_epochs'] = epoch + 1
    
    return model, history

def main():
    """
    Main training pipeline for normalized color channel DR classification
    """
    # Configuration - you can change normalization_type here
    config = {
        'train_csv': '/kaggle/input/aptos2019-blindness-detection/train.csv',
        'test_csv': '/kaggle/input/aptos2019-blindness-detection/test.csv',
        'train_img_dir': '/kaggle/input/aptos2019-blindness-detection/train_images',
        'test_img_dir': '/kaggle/input/aptos2019-blindness-detection/test_images',
        'batch_size': 16,
        'num_epochs': 50,
        'learning_rate': 1e-4,
        'num_classes': 5,
        'dropout_rate': 0.5,
        'normalization_type': 'rg_ratio'  # Options: 'rg_ratio', 'rgb_ratio', 'combined'
    }
    
    # Determine number of input channels based on normalization type
    channel_mapping = {
        'rg_ratio': 2,      # R/(R+G), G/(R+G)
        'rgb_ratio': 3,     # R/(R+G+B), G/(R+G+B), B/(R+G+B)  
        'combined': 6       # RGB + normalized ratios
    }
    
    input_channels = channel_mapping[config['normalization_type']]
    
    print("="*70)
    print("DIABETIC RETINOPATHY NORMALIZED COLOR MODEL")
    print("="*70)
    print("Configuration:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    print(f"  input_channels: {input_channels}")
    print("="*70)
    
    # Get transforms for normalized channels
    train_transforms, val_transforms = get_normalized_transforms(input_channels)
    
    # Load training data with normalized channels
    print(f"\nLoading training data with {config['normalization_type']} normalization...")
    full_train_dataset = DiabeticRetinopathyNormalizedDataset(
        csv_file=config['train_csv'],
        img_dir=config['train_img_dir'],
        transform=train_transforms,
        normalization_type=config['normalization_type']
    )
    
    # Split into train and validation
    train_size = int(0.8 * len(full_train_dataset))
    val_size = len(full_train_dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_train_dataset, [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )
    
    # Create data loaders
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config['batch_size'], 
        shuffle=True, 
        num_workers=4,
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=4,
        pin_memory=True
    )
    
    # Load test data
    test_dataset = DiabeticRetinopathyNormalizedDataset(
        csv_file=config['test_csv'],
        img_dir=config['test_img_dir'],
        transform=val_transforms,
        is_test=True,
        normalization_type=config['normalization_type']
    )
    test_loader = DataLoader(
        test_dataset, 
        batch_size=config['batch_size'], 
        shuffle=False, 
        num_workers=4,
        pin_memory=True
    )
    
    # Initialize model with correct input channels
    print(f"\nInitializing model with {input_channels} input channels...")
    model = DRNormalizedClassifier(
        num_classes=config['num_classes'],
        dropout_rate=config['dropout_rate'],
        input_channels=input_channels
    )
    model.to(device)
    
    # Print model information
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    
    # Train model
    print("\nStarting normalized color model training...")
    model, history = train_normalized_model(
        model, 
        train_loader, 
        val_loader, 
        num_epochs=config['num_epochs'],
        learning_rate=config['learning_rate']
    )
    
    # Print final results
    print("\n" + "="*70)
    print("NORMALIZED COLOR MODEL - FINAL RESULTS")
    print("="*70)
    print(f"Normalization Type: {config['normalization_type']}")
    print(f"Input Channels: {input_channels}")
    print(f"Best QWK Score: {history['best_kappa']:.4f}")
    print(f"Total Epochs: {history['total_epochs']}")
    
    if history['best_kappa'] > 0.889:
        print("✅ Target QWK score (>0.889) achieved!")
    else:
        print("❌ Target QWK score (>0.889) not yet achieved.")
        print(f"   Gap to target: {0.889 - history['best_kappa']:.4f}")
    
    return model, history

if __name__ == "__main__":
    # Set random seeds for reproducibility
    torch.manual_seed(42)
    np.random.seed(42)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    # Run normalized color experiment
    model, history = main()
